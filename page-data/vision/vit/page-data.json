{"componentChunkName":"component---src-templates-blog-post-js","path":"/vision/vit/","result":{"data":{"site":{"siteMetadata":{"title":"Deep Learner","author":"[Jeonsworld]","siteUrl":"https:jeonsworld.github.io","comment":{"disqusShortName":"","utterances":"jeonsworld/blog-comment"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"1272792c-f9e0-5c94-ae23-1be39c1bd8df","excerpt":"An Image is Worth 16X16 Words: Transformers for Image Recognition at Scale Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby…","html":"<blockquote>\n<p><strong>An Image is Worth 16X16 Words: Transformers for Image Recognition at Scale</strong><br>\nAlexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, Jakob Uszkoreit, Neil Houlsby<br>\n<a href=\"https://arxiv.org/abs/2010.11929\">https://arxiv.org/abs/2010.11929</a></p>\n</blockquote>\n<h1 id=\"abstract\" style=\"position:relative;\"><a href=\"#abstract\" aria-label=\"abstract permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Abstract</h1>\n<p> Transformer architecture는 NLP task에서는 표준이 되었지만 computer vison task에서는 아직 제한적이다.\nComputer vision task에서 attention은 CNN과 함께 적용되거나 전체구조를 유지하면서 CNN의 특성 요소를 대체하는데 사용된다.<br>\n본 논문에서는 CNN에 대한 이러한 의존이 필요하지 않으며 image patch의 seqeuence가 transformer에 적용될 때 image classification task에서 잘 수행될 수 있음을 보여준다.<br>\n많은 양의 데이터에 대해 사전 학습을 수행하고 여러가지 recognition benchmark(ImageNet, CIFAR-100, VTAB 등)에 대해 transfer learning을 수행하면 Vision Transformer는 훨씬 적은 computational resource를 가지며 동시에 SotA CNN과 비교하여 더 우수한 결과를 얻을 수 있다.</p>\n<h1 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Introduction</h1>\n<p>Transformers는 NLP에서 선택되는 모델이 되었다.\n대부분의 접근 방식은 large text corpus에서 pre-train을 수행하고 task-specific dataset에 대해 fine-tuning을 수행하는 것이다(BERT).\nTransformers의 계산 효율성 및 확장성으로 100B 이상의 parameter를 사용하여 전례없는 크기의 모델을 학습 할 수 있게 되었다.</p>\n<p>그러나 computer vision에서는 CNN이 여전히 많이 사용된다.\nNLP 성공에 영감을 받아 여러 연구들에서 CNN과 유사한 architecture를 self-attention과 결합하려고 시도하며(<a href=\"https://arxiv.org/abs/1906.01787\">Wang et al., 2018</a>; <a href=\"https://arxiv.org/abs/2005.12872\">Carion et al., 2020</a>) 일부는 CNN을 완전히 대체한다(<a href=\"https://arxiv.org/abs/1906.05909\">Ramachandran et al., 2019</a>; <a href=\"https://arxiv.org/abs/2003.07853\">Wang et al. , 2020a</a>).<br>\n후자의 연구들은 이론적으로는 효율적이지만 specialized attention pattern을 사용하기 때문에 최신 하드웨어 가속기에서는 아직 효과적으로 사용하기 어렵다. 따라서 large-scale image recognition task에서 ResNet-like architecture는 여전히 SotA.</p>\n<p>NLP의 Transformer 성공에 영감을 받아, 가능한 최소한의 수정으로 Transformer를 이미지에 직접 적용하는 실험을한다. 이를 위해 image를 patch로 분할하고 이러한 패치의 linear embedding sequence를 Transformer에 대한 입력으로 feed한다. Image patch는 NLP 애플리케이션의 token(word)과 동일한 방식으로 처리된다.</p>\n<p>이러한 모델은 ImageNet과 같은 중간 규모의 dataset에서 학습할때 적당한 결과를 산출하여 비슷한 크기의 ResNet보다 조금 아래의 정확도를 달성한다. 이는 겉보기에 실망스러운 결과를 예상 할 수 있다. Transformer는 translation equivariance 및 locality와 같은 CNN 고유의 inductive bias가 없기 때문에 불충분한 양의 data에 대해 학습할 때 일반화가 잘 되지 않는다.</p>\n<p>그러나 large-scale dataset(14M-300M Images)에서 모델을 학습하면 이와 다르다. large-scale training이 inductive bias를 능가한다는 것을 알게 되었다. Transformer는 충분한 규모로 사전 학습되고 더 적은 데이터 포인트가있는 작업으로 전송 될 때 좋은 결과를 얻는다.<br>\nJFT-300M 데이터 세트에 대해 사전 훈련 된 Vision Transformer는 여러 Image Recognition Benchmark에서 SotA에 접근하거나 이를 능가하여 ImageNet에서 88.36%, ImageNet-ReaL에서 90.77%, CIFAR-100에서 94.55%, 77.16%의 정확도를 달성했다.</p>\n<h1 id=\"2-related-work\" style=\"position:relative;\"><a href=\"#2-related-work\" aria-label=\"2 related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Related Work</h1>\n<p>Transformer는 NMT(Neural Machine Translation)을 위한것이며 많은 NLP task에서 SotA를 달성했다.\nLarge Transformer-based model은 종종 large-scale corpus에 대해 pre-train을 수행하고 해당되는 task에 fine-tuning을 수행한다.\nBERT는 denoising self-supervised pre-training task를 사용하는 반면 GPT 계열은 language modeling방식으로 pre-train을 수행한다.</p>\n<p>Self-attention을 image에 naive하게 적용하려면 각 픽셀이 다른 모든 픽셀에 attention해야한다.\n이는 픽셀수의 quadratic cost를 가지고 실제 input size로 확장되지 않는다.\n따라서 image generation 측면에서 Transformer를 적용하기 위해 시도된 몇 가지 연구들이 있다.</p>\n<p>가장 최근의 연구인 <a href=\"https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf\">iGPT</a>는 image resolution과 color sapce를 줄인 후 이미지에 대해 transformer를 적용한다. Model은 unsupervised 방식으로 학습되고 이후 fine-tuning을 수행하거나 linear를 수행하여 ImageNet에서 72%의 정확도를 달성하였다. 해당 연구는 SotA결과를 얻기 위해 추가적인 데이터에 의존한다.</p>\n<p><a href=\"https://arxiv.org/abs/1707.02968\">Sun et al.(2017)</a>은 CNN 성능이 dataset 크기에 따라 어떻게 확장되는지 연구하고 <a href=\"https://arxiv.org/abs/1912.11370\">Kolesnikov et al. (2020)</a>; <a href=\"https://arxiv.org/abs/2007.08558\">Djolonga et al. (2020)</a>은 ImageNet-21k 및 JFT-300M과 같은 large-scale dataset에서 CNN transfer learning에 대한 경험적 탐색을 수행하며, 모두 본 논문이 초점을 두고 있다.</p>\n<h1 id=\"3-method\" style=\"position:relative;\"><a href=\"#3-method\" aria-label=\"3 method permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Method</h1>\n<h2 id=\"31-vision-transformervit\" style=\"position:relative;\"><a href=\"#31-vision-transformervit\" aria-label=\"31 vision transformervit permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1 Vision Transformer(ViT)</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 60.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACQ0lEQVQoz41T2W7aQBT19/elUl/70IeqUh9aqarUJQohIkWQeAl4HZulGGxsA15YDCQF+/R6KJHSh6pXOpo7d67PnJk5FsqyRBWHhx0e85TnSbZCEAQcURRhu93yetV7xmKxwKDfI/TheR6OxyPvEcqiOJEMZTj1t0j9HoL7r/hXFPRNGEbo6Ax3igrLdlA8EZYnwnxqITEukYQu+uJ35JsNV3ZGnufYUG2333OFfhCifq+h3jHQtRiOh19nwvLZ7tlqjUkQwfd9MMY4TNOE67qYeBNMp1M6XoFZ6GGofgYT34NpbaqdeITz3VQKttsd0iSBZRhgtKtFMHUTpmHCcXqwTIsTVhFGAUStiYZ4CdXo0JGL5wrd8RiGrmOZLeH/HGGoyOhLIqxbEY4ogd2JMFq3SDyf93tTF59u3uDD9WsoRpsIy+eEBhvh3RcFu8cC+XqN2pWIiysZUquNZqNFaKJVv4CtqyeFwQSm8hE6HdnS2zgc/lJ4Xa/hxctXyJZrUpnhRnJQk1xYzIZuMvxo3+K6UUOPrFLFKktJfRNS7Rsib/xkK+H8GA8Pe+z3Of4nuAiyTkb3mZAHy8PhaU0IwwBzMmlMmM3n3MhxHHOfVZj+MfdsNsOMxojGOfWFYYg4TbGg3jiJea3KBce20e2q3B6aqkLTNNg2I9g8V1UNsizDIOtUNZ0cUNW73S4kSYJCj2eTsRVFgUFrguuOeINOLzwcDPhYNTiOw723Wq24woTstFwuudLqt6vmcbw4KaP5qZbiN9LAdeAZ3Y7rAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig1\"\n        title=\"fig1\"\n        src=\"/static/e6cc6a6253b181016721906d16a26a96/fcda8/fig1.png\"\n        srcset=\"/static/e6cc6a6253b181016721906d16a26a96/12f09/fig1.png 148w,\n/static/e6cc6a6253b181016721906d16a26a96/e4a3f/fig1.png 295w,\n/static/e6cc6a6253b181016721906d16a26a96/fcda8/fig1.png 590w,\n/static/e6cc6a6253b181016721906d16a26a96/4ff83/fig1.png 843w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p> 이미지용 Transformer는 NLP용으로 설계된 architecture를 따르며 그림1과 같다.\nStandard Transformer는 token embedding의 1D sequence를 입력으로 받는다.<br>\n이미지를 처리하기 위해 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">x</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mi>H</mi><mo>×</mo><mi>W</mi><mo>×</mo><mi>C</mi></mrow></msup></mrow><annotation encoding=\"application/x-tex\">\\mathbf{x}\\in \\mathbb{ R }^{ H\\times W\\times C }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8413309999999999em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.08125em;\">H</span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">W</span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span></span></span></span></span></span></span></span></span></span></span></span> 를 flatten된 2D patch <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>x</mi><mi>p</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>N</mi><mo>×</mo><mrow><mo fence=\"true\">(</mo><msup><mi>P</mi><mn>2</mn></msup><mo>⋅</mo><mi>C</mi><mo fence=\"true\">)</mo></mrow></mrow></msup></mrow><annotation encoding=\"application/x-tex\">{ x }_{ p }\\in { R }^{ N\\times \\left( { P }^{ 2 }\\cdot C \\right)  }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8252079999999999em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.10775em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.00773em;\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.10775em;\"><span style=\"top:-3.4102500000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">×</span><span class=\"minner mtight\"><span class=\"mopen sizing reset-size3 size6 mtight delimcenter\" style=\"top:0.07500000000000001em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913142857142857em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">⋅</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose sizing reset-size3 size6 mtight delimcenter\" style=\"top:0.07500000000000001em;\"><span class=\"mtight\">)</span></span></span></span></span></span></span></span></span></span></span></span></span></span> sequence로 재구성한다.<br>\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">(</mo><mi>H</mi><mo separator=\"true\">,</mo><mi>W</mi><mo fence=\"true\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\left( H,W \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span>는 원본 이미지의 resolution이고 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">(</mo><mi>P</mi><mo separator=\"true\">,</mo><mi>P</mi><mo fence=\"true\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\left( P,P \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span> 는 각 이미지 patch의 resolution이다.\n<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>N</mi><mo>=</mo><mi>H</mi><mi>W</mi><mi mathvariant=\"normal\">/</mi><msup><mi>P</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">N=HW/{ P }^{ 2 }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">N</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.064108em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">W</span><span class=\"mord\">/</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span></span></span></span>는 Transformer의 sequence length이다.<br>\nTransformer는 모든 layer를 일정한 width를 사용하므로 학습 가능한 linear projection은 각 vectorized patch를 dimension <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi></mrow><annotation encoding=\"application/x-tex\">D</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span></span></span></span>(식 1)에 mapping하며, 그 결과를 patch embedding이라고 한다.</p>\n<p>BERT의 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[class]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">s</span><span class=\"mclose\">]</span></span></span></span> token과 유사하게 Transformer encoder의 output state <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">(</mo><msubsup><mi>z</mi><mn>0</mn><mi>L</mi></msubsup><mo fence=\"true\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\left( { z }_{ 0 }^{ L } \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8413309999999999em;\"><span style=\"top:-2.4518920000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">L</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span></span></span></span>가 image representation <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>y</mi></mrow><annotation encoding=\"application/x-tex\">y</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span></span></span>로 사용되는 embedded patch의 sequence <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">(</mo><msubsup><mi>z</mi><mn>0</mn><mn>0</mn></msubsup><mo>=</mo><msub><mi>x</mi><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msub><mo fence=\"true\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\left( { z }_{ 0 }^{ 0 }={ x }_{ class } \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.4518920000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.24810799999999997em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">c</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span></span></span></span> 앞에 학습 가능한 embedding을 추가한다(식 4).<br>\nPre-train 및 fine-tuning중에 classification head는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">(</mo><msubsup><mi>z</mi><mi>L</mi><mn>0</mn></msubsup><mo fence=\"true\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\left( { z }_{ L }^{ 0 } \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8141079999999999em;\"><span style=\"top:-2.424669em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">L</span></span></span></span><span style=\"top:-3.063em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.275331em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span></span></span></span> 에 추가된다.</p>\n<p>Position embedding은 위치 정보를 유지하기 위해 patch embedding에 더해진다.<br>\nAppendix C.3에서 position embedding의 2D-aware variants에 대해 탐색한다.</p>\n<p>Transformer Encoder는 Multi-headed self-attention 및 MLP block으로 구성된다. Layernorm(LN)은 모든 block 이전에 적용되고 residual connection은 모든 block 이후에 적용된다.  </p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"bold\">z</mi><mn>0</mn></msub><mo>=</mo><mrow><mo fence=\"true\">[</mo><msub><mi mathvariant=\"bold\">x</mi><mrow><mi>c</mi><mi>l</mi><mi>a</mi><mi>s</mi><mi>s</mi></mrow></msub><mo separator=\"true\">;</mo><msubsup><mi mathvariant=\"bold\">x</mi><mi>p</mi><mn>1</mn></msubsup><mi mathvariant=\"bold\">E</mi><mo separator=\"true\">;</mo><msubsup><mi mathvariant=\"bold\">x</mi><mi>p</mi><mn>2</mn></msubsup><mi mathvariant=\"bold\">E</mi><mo separator=\"true\">;</mo><mo>⋯</mo><mtext> </mtext><mo separator=\"true\">;</mo><msubsup><mi mathvariant=\"bold\">x</mi><mi>p</mi><mi>N</mi></msubsup><mi mathvariant=\"bold\">E</mi><mo fence=\"true\">]</mo></mrow><mo>+</mo><msub><mi mathvariant=\"bold\">E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mi mathvariant=\"bold\">E</mi><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mrow><mo fence=\"true\">(</mo><msup><mi>p</mi><mn>2</mn></msup><mo>⋅</mo><mi>C</mi><mo fence=\"true\">)</mo></mrow><mo>×</mo><mi>D</mi></mrow></msup><mo separator=\"true\">,</mo><msub><mi mathvariant=\"bold\">E</mi><mrow><mi>p</mi><mi>o</mi><mi>s</mi></mrow></msub><mo>∈</mo><msup><mi mathvariant=\"double-struck\">R</mi><mrow><mrow><mo fence=\"true\">(</mo><mi>N</mi><mo>+</mo><mn>1</mn><mo fence=\"true\">)</mo></mrow><mo>×</mo><mi>D</mi></mrow></msup><mspace width=\"1em\"/><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbf{ z }_{ 0 }=\\left[ \\mathbf{ x }_{ class };\\mathbf{ x }_{ p }^{ 1 }\\mathbf{E};\\mathbf{ x }_{ p }^{ 2 }\\mathbf{E};\\cdots ;\\mathbf{ x }_{ p }^{ N }\\mathbf{E} \\right] +\\mathbf{ E }_{ pos },\\quad \\mathbf{E}\\in \\mathbb{ R }^{ \\left( { p }^{ 2 }\\cdot C \\right) \\times D },\\mathbf{ E }_{ pos }\\in \\mathbb{ R }^{ \\left( N+1 \\right) \\times D }\\quad (1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.59444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.274439em;vertical-align:-0.383108em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">[</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">c</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.01968em;\">l</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">s</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.864108em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathbf\">E</span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.864108em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathbf\">E</span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">⋯</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.891331em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span></span></span></span><span style=\"top:-3.1130000000000004em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.383108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord mathbf\">E</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">]</span></span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.972218em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">E</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.396608em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.1105em;\"><span style=\"top:-3.4130000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen sizing reset-size3 size6 mtight delimcenter\" style=\"top:0.07500000000000001em;\"><span class=\"mtight\">(</span></span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8913142857142857em;\"><span style=\"top:-2.931em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mbin mtight\">⋅</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.07153em;\">C</span><span class=\"mclose sizing reset-size3 size6 mtight delimcenter\" style=\"top:0.07500000000000001em;\"><span class=\"mtight\">)</span></span></span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\">o</span><span class=\"mord mathdefault mtight\">s</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∈</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.188em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbb\">R</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.938em;\"><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span><span class=\"mbin mtight\">+</span><span class=\"mord mtight\">1</span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span><span class=\"mbin mtight\">×</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">D</span></span></span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></span>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msubsup><mi mathvariant=\"bold\">z</mi><mi mathvariant=\"normal\">ℓ</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo>=</mo><mrow><mi mathvariant=\"normal\">M</mi><mi mathvariant=\"normal\">S</mi><mi mathvariant=\"normal\">A</mi></mrow><mrow><mo fence=\"true\">(</mo><mrow><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">N</mi></mrow><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"bold\">z</mi><mrow><mi mathvariant=\"normal\">ℓ</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow><mo>+</mo><msub><mi mathvariant=\"bold\">z</mi><mrow><mi mathvariant=\"normal\">ℓ</mi><mo>−</mo><mn>1</mn></mrow></msub><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mi mathvariant=\"normal\">ℓ</mi><mo>=</mo><mn>1</mn><mo>…</mo><mi>L</mi><mspace width=\"1em\"/><mo stretchy=\"false\">(</mo><mn>2</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbf{ z }_{ \\ell  }^{ \\prime  }=\\mathrm{MSA}\\left( \\mathrm{LN}\\left( \\mathbf{ z }_{ \\ell -1 } \\right)  \\right) +\\mathbf{ z }_{ \\ell -1 },\\quad \\ell =1\\dots L\\quad (2)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.048892em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8018919999999999em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">ℓ</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">M</span><span class=\"mord mathrm\">S</span><span class=\"mord mathrm\">A</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathrm\">L</span><span class=\"mord mathrm\">N</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">ℓ</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.902771em;vertical-align:-0.208331em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">ℓ</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord\">ℓ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">2</span><span class=\"mclose\">)</span></span></span></span></span>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"bold\">z</mi><mi mathvariant=\"normal\">ℓ</mi></msub><mo>=</mo><mrow><mi mathvariant=\"normal\">M</mi><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">P</mi></mrow><mrow><mo fence=\"true\">(</mo><mrow><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">N</mi></mrow><mrow><mo fence=\"true\">(</mo><msubsup><mi mathvariant=\"bold\">z</mi><mi mathvariant=\"normal\">ℓ</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow><mo>+</mo><msubsup><mi mathvariant=\"bold\">z</mi><mi mathvariant=\"normal\">ℓ</mi><mo mathvariant=\"normal\" lspace=\"0em\" rspace=\"0em\">′</mo></msubsup><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mi mathvariant=\"normal\">ℓ</mi><mo>=</mo><mn>1</mn><mo>…</mo><mi>L</mi><mspace width=\"1em\"/><mo stretchy=\"false\">(</mo><mn>3</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbf{ z }_{ \\ell  }=\\mathrm{MLP}\\left( \\mathrm{LN}\\left( \\mathbf{ z }_{ \\ell  }^{ \\prime  } \\right)  \\right) +\\mathbf{ z }_{ \\ell  }^{ \\prime  },\\quad \\ell =1\\dots L\\quad (3)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.59444em;vertical-align:-0.15em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">ℓ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.051892em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">M</span><span class=\"mord mathrm\">L</span><span class=\"mord mathrm\">P</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathrm\">L</span><span class=\"mord mathrm\">N</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8018919999999999em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">ℓ</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.048892em;vertical-align:-0.247em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8018919999999999em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">ℓ</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">′</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mord\">ℓ</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\">1</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">L</span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">3</span><span class=\"mclose\">)</span></span></span></span></span>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">y</mi><mo>=</mo><mrow><mi mathvariant=\"normal\">L</mi><mi mathvariant=\"normal\">N</mi></mrow><mrow><mo fence=\"true\">(</mo><msubsup><mi mathvariant=\"bold\">z</mi><mi>L</mi><mn>0</mn></msubsup><mo fence=\"true\">)</mo></mrow><mspace width=\"1em\"/><mo stretchy=\"false\">(</mo><mn>4</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathbf{y}=\\mathrm{LN}\\left( \\mathbf{ z }_{ L }^{ 0 } \\right) \\quad (4)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.63888em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">y</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.2141179999999998em;vertical-align:-0.35001em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">L</span><span class=\"mord mathrm\">N</span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">(</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\">z</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">L</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">4</span><span class=\"mclose\">)</span></span></span></span></span>\n<p><strong>Hybrid Architecture.</strong><br>\n이미지를 patch로 나누는 대신 ResNet의 중간 feature map에서 input sequence를 형성할 수 있다.<br>\nHybrid Model에서 patch embedding projection <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">E</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{E}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68611em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">E</span></span></span></span></span>(식 1) 는 ResNet의 early stage로 대체된다.<br>\nResNet의 중간 2D feature map중 하나는 sequence로 flatten되고 transformer dimension에 projection된 다음 transformer의 input sequence로 feed된다.<br>\nClassification input embedding 및 position embedding은 위에서 설명한대로 transformer에 대한 input에 추가된다.</p>\n<h2 id=\"32-fine-tuning-and-higher-resolution\" style=\"position:relative;\"><a href=\"#32-fine-tuning-and-higher-resolution\" aria-label=\"32 fine tuning and higher resolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.2 Fine-tuning and Higher Resolution</h2>\n<p>일반적으로 large-scale dataset에 대해 ViT를 pre-train하고 downstream task에 대해 fine-tuning을 수행한다.\n이를 위해 pre-trained prediction head를 제거하고 0으로 초기화된 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>D</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">D\\times K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.76666em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">D</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span></span></span></span> feedforward layer를 추가한다.\n여기서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>K</mi></mrow><annotation encoding=\"application/x-tex\">K</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span></span></span></span>는 downstream class의 개수이다.</p>\n<p>Pre-train 보다 높은 resolution으로 fine-tuning하는것은 종종 도움이 된다.\n더 높은 resolution의 이미지를 feed할 때 patch 크기를 동일하게 유지하므로 sequence length가 더 길어진다.\nVision Transformer는 임의의 sequence length를 처리할 수 있지만 pre-trained position embedding은 의미가 없을 수 있다.\n따라서 원본 이미지에서의 위치에 따라 pre-trained position embedding의 2D interpolation을 수행한다.\nResolution 조정 및 patch 추출은 이미지의 2D 구조에 대한 inductive bias가 Vision Transformer에 수동으로 주입되는 유일한 지점이다.</p>\n<h1 id=\"4-experiments\" style=\"position:relative;\"><a href=\"#4-experiments\" aria-label=\"4 experiments permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Experiments</h1>\n<p>ResNet, Vision Transformer(ViT) 및 Hybrid에 대해 representation learning 검증을 수행한다.\n다양한 크기의 dataset에 대해 pre-train하고 benchmark를 수행한다.</p>\n<p>pre-training 계산비용을 고려할 때 ViT는 더 낮은 비용으로 대부분의 recognition benchmark에서 SotA를 달성하였다.</p>\n<h2 id=\"41-setup\" style=\"position:relative;\"><a href=\"#41-setup\" aria-label=\"41 setup permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.1 Setup</h2>\n<p><strong>Datasets.</strong><br>\nPre-train dataset</p>\n<ul>\n<li>ILSVRC-2012 ImageNet dataset(ImageNet) - 1k 클래스 및 1.3M 이미지</li>\n<li>ImageNet-21k - 21,000 클래스 및 14M 이미지</li>\n<li>JFT - 18k 클래스 및 303M 이미지</li>\n</ul>\n<p>Transfer Learning dataset</p>\n<ul>\n<li>ImageNet 및 ReaL labels</li>\n<li>CIFAR 10/100</li>\n<li>Oxford-IIIT Pets</li>\n<li>Oxford Flowers-102</li>\n<li>19-task VTAB classification suite</li>\n</ul>\n<p><strong>Model Variants.</strong></p>\n<ul>\n<li>BERT에 사용되는 구성을 기반으로 함.</li>\n<li>접미사는 “B”(Base), “L”(Large), “H”(Huge) 를 뜻함.</li>\n<li>예를들어 ViT-L/16 의 경우는 Large 사이즈 이며 16x16 의 패치크기를 가짐.</li>\n</ul>\n<p><strong>Training &#x26; Fine-tuning.</strong><br>\nPre-train</p>\n<ul>\n<li>Adam optimizer, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>β</mi><mn>1</mn></msub><mo>=</mo><mn>0.9</mn><mo separator=\"true\">,</mo><msub><mi>β</mi><mn>2</mn></msub><mo>=</mo><mn>0.999</mn><mo separator=\"true\">,</mo><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>4096</mn></mrow><annotation encoding=\"application/x-tex\">{ \\beta  }_{ 1 }=0.9,{ \\beta  }_{ 2 }=0.999, batch size=4096</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">9</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05278em;\">β</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.8888799999999999em;vertical-align:-0.19444em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">9</span><span class=\"mord\">9</span><span class=\"mord\">9</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">h</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">4</span><span class=\"mord\">0</span><span class=\"mord\">9</span><span class=\"mord\">6</span></span></span></span></li>\n<li>weight decay: 0.1</li>\n</ul>\n<p>Fine-tuning</p>\n<ul>\n<li>SGD w/ momentum, <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>b</mi><mi>a</mi><mi>t</mi><mi>c</mi><mi>h</mi><mi>s</mi><mi>i</mi><mi>z</mi><mi>e</mi><mo>=</mo><mn>512</mn></mrow><annotation encoding=\"application/x-tex\">batch size=512</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">b</span><span class=\"mord mathdefault\">a</span><span class=\"mord mathdefault\">t</span><span class=\"mord mathdefault\">c</span><span class=\"mord mathdefault\">h</span><span class=\"mord mathdefault\">s</span><span class=\"mord mathdefault\">i</span><span class=\"mord mathdefault\" style=\"margin-right:0.04398em;\">z</span><span class=\"mord mathdefault\">e</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">5</span><span class=\"mord\">1</span><span class=\"mord\">2</span></span></span></span></li>\n<li>using linear learning rate warmup and decay</li>\n<li>Higher resolution: 512 for ViT-L/16 and 518 for ViT-H/14</li>\n</ul>\n<h2 id=\"42-comparison-to-state-of-the-art\" style=\"position:relative;\"><a href=\"#42-comparison-to-state-of-the-art\" aria-label=\"42 comparison to state of the art permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.2 Comparison to State of the Art</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABmUlEQVQoz01SCZKCMBDM/5/mUSKXeIGIIOCJCopX7/S4bm2qQshMptPdE/N6vfB4PHTe73ed12uDMAyRpqnG8zxHFEUSv2K33SIYBSiKEufzGeMgwHg8RiBr27Yw/BRFjrIs0UhB297R3m6YzWaI41j2NwVbLBbYbDZYr7O/3OlUIZa4bdtYLpdKxjRNg36vB9/3tYCjrmtMp1MUvETyBFytUmwlT5Ys3u12evb5fCDLMlHy1L1hcTDy5RbnDzCKQtiOI+uHFcHJcL/fC8O1/vMSMuKgbe/3W6ehX45jYzi0MbAsbMWjNF3BdV0tKooCnucqOHNJkmAymSjof8DvMDeRQAYsoPl13Yg3J23IWvaXy0VBk2WiTaiqSkEPh4PKpyWfulrkP2Gq41EbwiImjrLnYcbIiACUzQsomTMX2czTx09uhVzqScSw7ZTn+x4skexIxyxrqLHBYKBe+p6HXr+PbrerHXUcVywaaiO5unKm0+lo9w2fAf2IpXOZsOD/fB6qrIV4SGbpb5ySKZHyrs1H7lc2lfAJ/gCywJ0VDuKr9AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table2\"\n        title=\"table2\"\n        src=\"/static/24ca0bc34bf08973c94f5e78797a8dce/fcda8/table2.png\"\n        srcset=\"/static/24ca0bc34bf08973c94f5e78797a8dce/12f09/table2.png 148w,\n/static/24ca0bc34bf08973c94f5e78797a8dce/e4a3f/table2.png 295w,\n/static/24ca0bc34bf08973c94f5e78797a8dce/fcda8/table2.png 590w,\n/static/24ca0bc34bf08973c94f5e78797a8dce/33e10/table2.png 844w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>모든 모델은 TPUv3에서 학습되었으며 pre-train에 소요된 일수를 확인할 수 있다.</p>\n<p>ViT-L/16 모델은 모든 dataset에서 BiT-L과 일치하거나 더 좋은 성능을 보여줌과 동시에 훨씬 적은 computational resource를 필요로 한다.\n더 큰 모델인 Vit-H/14는 ImageNet 및 CIFAR-100과 VTAB에서 성능이 더욱 향상되었다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.08108108108108%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABcElEQVQY0yWRXWsTQRSG9+/2LxS8KvRKBO+MxRYqlKatRSRgUlqxH6m2KGKNRBFJTCEfM7uzm92ku9mdmcfZ6TAwZ973OYdzZoKH5ZLFQ86fieJeKJJYkbt7JuZEMiIMQ5bZglEsuZczkiRGJXPydEYWjZhIRbbIqJc2mqDI5nR6QxqvzqF021pnWU56/zh43YVCU9Wa1Rzf/uZD+4dPLg2ea3Z/8aZzyyAJvR7k85jW9wFPNo45/XrNShfe2L3u8/xpG/LCaaVPfnl2x8bmWzrdJmU69lyjfcfa+hYvPu7VPRLg4G+DCTv7l2y9a6DGPQ9e9YfsH33i802LVP712smXPtvNC7aPNsnGP732/qbPzuE5B61nlGroCvrODcYVtpWhqjS2HtG9R1WtXIMFWhtqSZerR86NW2qLMQbtGGsqd1oqYwnEbIZSMVKGTKdT4jhGCOFjISRRFDlfOV96r+aU+7goCn1c+zKsY0GapvwHWXi4v1FdzMAAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig2\"\n        title=\"fig2\"\n        src=\"/static/7c8a03d1186558cd8438618211152449/fcda8/fig2.png\"\n        srcset=\"/static/7c8a03d1186558cd8438618211152449/12f09/fig2.png 148w,\n/static/7c8a03d1186558cd8438618211152449/e4a3f/fig2.png 295w,\n/static/7c8a03d1186558cd8438618211152449/fcda8/fig2.png 590w,\n/static/7c8a03d1186558cd8438618211152449/f73a1/fig2.png 822w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>VTAB task에 대해 각각의 그룹으로 분할하고 이전 SotA와 비교함.</p>\n<h2 id=\"43-pre-training-data-requirements\" style=\"position:relative;\"><a href=\"#43-pre-training-data-requirements\" aria-label=\"43 pre training data requirements permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.3 Pre-training Data Requirements</h2>\n<p>ViT는 large-scale JFT-300M dataset에서 pre-train 하였을 때 좋은 성능을 보여준다.\nResNet보다 vision에 대한 inductive bias가 적을때 dataset의 크기가 얼마나 중요한지에 대한 실험을 수행한다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 403px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 111.48648648648648%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAAAsTAAALEwEAmpwYAAADgUlEQVQ4y5VT27KiSBDk/z9qXndmdz1HVERQ5CIXERAFRQE1N6s9OO7G7MN0RAXQdGVlZWVr4GqaBmma4ng8/nZUVYXT6YS6rtH3PbTz+YzD4YCyLBXw/X5/xe12UyHvff98Ph731/N263EnoXD0DdvFBy7dDZqA5Xmuqgjg4/F4Acq7hKyuvTCuaNtOnZPzwq5pzlisXETJDtfL5cnQtm0kSYILN96ZtW2rkptzDdPfwU8KVMfDv1o+E3gdh0j3BS48q0kV0e96vaqKXdcpYNFEvg+HIys3GJse3DBV73V9UgyHKIpCnRdyiqGwy3YZinKPPbUUoPc4VTXcyEOap19FDq+o6wq74oDq1BDwBE1ou2sXeZGjythSefjPFGuyvyDbk0FzVTJIBxIihxBSrfMpbBVgyUp932Jkxgi3JfquVYmvwagp90qOn8N6ai17EsOgNLGL4zjYsu1ddVajf7wNRkLYSHvL5RINNbzTQtmJre73CDcb+L6vdFQaykHZ6MhItGi7/uW1IWTv1LQIggCr1QolJ5oeG2zzEnEUqvwsy56AInIUR6g4TTePce6uAK33Yni/ob92uNYESLfwPQ9ZUaL2Dew3DpI0I6D35UnaRkwria7rwlwsFIM9WxFtxQrSwcBsw/a22y1qJpdfbpB/IoVhGOqsNtwE0SnlYbk1UmDYEwDLsqDrOjyyk0sgeg1ruDHiZTmvGN7vD/xqyQFJHq6nvO92O/V8v5bvS3v/GA796uD/rcFGL8BwE+BzrCsdhLp4Uu7ubGaovblpUq89GWZKr+l0hvncwHg85q06KpA59Rt9fKppa3EY4K/RBxJq5VD4gMJLsiRMp1PEcawGIqLL/5h+nc1mT+9SN9uyecsK/Pn9D6w9AtqWidHnGBOKHgQbFNRKJ9iPH9+x5uRlEFMCyH3X2YkUTGiz+dxEQLv8PRqpgh7B4jghQ/4UJrPpBAtO03HWMNjughayWD0KQ0oyVpaRaX+wtcB3YRDQWS2ZO8FkMoVPMu56TcDomRCwf9HmU5/AojVyOt8gM8tm0mTCf3PVorzb1gL28imD57kK0KTWUlRLog0+2LJtWzCZJJXFcxG12yYx/+ncNxSg63Mo+hg6AcSzK9GRTwFecYBiKS3PdgRbqqrmwlLXSFiYC1aMEljc2wQ+XGpks+U125L/rrOC43qqizCMXrb5B3Kydbs2IRMxAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig3\"\n        title=\"fig3\"\n        src=\"/static/50784470c674f7896b39435fed591425/045fd/fig3.png\"\n        srcset=\"/static/50784470c674f7896b39435fed591425/12f09/fig3.png 148w,\n/static/50784470c674f7896b39435fed591425/e4a3f/fig3.png 295w,\n/static/50784470c674f7896b39435fed591425/045fd/fig3.png 403w\"\n        sizes=\"(max-width: 403px) 100vw, 403px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>가장 작은 dataset에 대해 pre-train을 수행한 경우 ViT-Large 모델은 정규화에도 불구하고 ViT-Base보다 성능이 떨어진다.\n그러나 ImageNet-21k dataset을 사용하면 성능이 비슷하다.\nJFT-300M dataset에서는 ViT가 BiT보다 더 좋은 성능을 보여줌을 확인할 수 있다.</p>\n<p>결과적으로 더 작은 dataset의 경우 convolutional inductive bias가 유리하지만 큰 dataset의 경우 관련 패턴을 학습하는 것이 충분하고 이점이 있다는 직감가질 수 있다.</p>\n<h2 id=\"44-scaling-study\" style=\"position:relative;\"><a href=\"#44-scaling-study\" aria-label=\"44 scaling study permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.4 Scaling Study</h2>\n<p>JFT-300M dataset에서 transfer performance에 대해 다양한 모델의 확장 연구를 수행한다.<br>\nDataset 크기는 모델 성능에 병목 현상이 없으며 각 모델의 pre-train 비용 대비 성능을 평가한다. 그림5에 transfer performance vs pre-training compute에 대한 내용이 있다.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 53.37837837837838%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAABu0lEQVQozz1Si26DMBDj/z+PtpSqnSpV6lb1wTM8kgCefYxFOpHkfD77SAKuEAK894gxomka3O93OOcQeR+CxzAM6Pv+DxNQliVutxu6rsPEmq1WK5mmaU3wGxnTNFsDFQYjjKiaFq5tLRfj9NdojW7wjBF1262E7/fb1GjNU0Tvanb1CH6EIzCQpKhqI8QyMxcwdjVJmXctPBtKyEDssixIiqIwO6aO9srGYaRFKRaALBiYlwvt/TjiVUltXPOMeZ4xjhvh52OH3kebleYxEyeQira5llQ5hAk9iTWOOM3rmJi3ejY1wg8JW9pZaEckWq4f8P3zwOV8xpbXWDxnpiKFMD/EfF0uhlkdcIYikW1dSGHX0V5doni/CCysuwirquJcvTlwriOmwOv1xPYPVG8KxSrQtmRBSmSzrms8Hg8WvvB8Pk2J7iTC+/Bfo6abu0R/SspEoC4iF0B7vTdFy5xcCNNQrXIKKVsdNP9vNcnzHNfrFccsw+FwwPF4RJYd7Zvn2mfY7/cWp1OOM+d6Op0sr0jTFLvdDnvG+fKFJE13NoeiKM2S9lIlm5tF7XWn86ZainXecJbjnH8BBUhNFtjcZngAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig5\"\n        title=\"fig5\"\n        src=\"/static/62f2245d55d8fc74eeb398b090aa9993/fcda8/fig5.png\"\n        srcset=\"/static/62f2245d55d8fc74eeb398b090aa9993/12f09/fig5.png 148w,\n/static/62f2245d55d8fc74eeb398b090aa9993/e4a3f/fig5.png 295w,\n/static/62f2245d55d8fc74eeb398b090aa9993/fcda8/fig5.png 590w,\n/static/62f2245d55d8fc74eeb398b090aa9993/5b481/fig5.png 846w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ol>\n<li>ViT는 performance/compute trade-off 에서 ResNet보다 효율적이다. ViT는 동일한 성능을 달성하기 위해 약 2배 적은 컴퓨팅을 사용함.</li>\n<li>Hybrid는 적은 computational cost에서 ViT를 능가하지만 큰 computational cost에서는 차이가 사라진다.</li>\n<li>ViT는 시도된 범위내에서 “saturate”되지 않는 것으로 보이며 향후 확장이 가능해보인다.</li>\n</ol>\n<h2 id=\"45-inspecting-vision-transformer\" style=\"position:relative;\"><a href=\"#45-inspecting-vision-transformer\" aria-label=\"45 inspecting vision transformer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.5 Inspecting Vision Transformer</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAACJ0lEQVQoz02SWU8aYRSG58f2L7QXTUzaqFCc0kAVsW6pMWlMrF1sJTZobLRXGpRVVGQbhk1GtgIzgPj0zLQX/ZI3Z87yvfOecz6lYRhksznOzyOcnZ05SKVSlCtl7o17xg8P5GslcjaqJbLVIkOrx+MjjMdjRqMRnW4Xy7J4kFpl4/0GM9PTuGZncb9yo6pzvFtawu/z82lnB1MueA4/oh585vXhF6b21sjWYliDEfVaDaNeIXN1RVXXaBkNlA9bW3hVLy9dL5jzeFjwBXgbmCcg+Hl0hNFp49rfRg1/xRve5dnuJic3CYb9AZqWJ5dO8LtlYJ/h0EJZX1/H55/H632D2+3Go6osBoIsB5c5CIe5azV5urvG8++bTIU2ebIV4CSaYmSZlHUZS7XqkDWlrtEQhdui0O124ff7WFldFWVBsSssStuhUAhLWl443iN4vM/Srx/MfNsmmcjKvKRlIev1ezI/E6NxR7PZRLGsIf1+n8FggCkJ0zSdAdv+UMicVkYm7W7LgTUcMJHh22cymdDtdDFksZ1ORxb1iKJpRWryp3q9TuYmQ6FQcFAq6eTzObElsQVuM7doRY18Lu/kNc2O56lUZCmZjLyULLquo9xcXxOJRDg9PSUejxFPJBw/Ho8TjV6QTqe5vLwkIb6ds+MJsbFYVBCT53ZOMpmU7795pSysNvO1EBeLRUeR/i+maZrj/x+z1dnKyuUyusTtmna7Ta/Xc/AHd/Fuor80u5QAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig7\"\n        title=\"fig7\"\n        src=\"/static/42e887598ea27aacf5b6cbdfadd196da/fcda8/fig7.png\"\n        srcset=\"/static/42e887598ea27aacf5b6cbdfadd196da/12f09/fig7.png 148w,\n/static/42e887598ea27aacf5b6cbdfadd196da/e4a3f/fig7.png 295w,\n/static/42e887598ea27aacf5b6cbdfadd196da/fcda8/fig7.png 590w,\n/static/42e887598ea27aacf5b6cbdfadd196da/8bd7c/fig7.png 845w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>ViT가 이미지를 처리하는 방법을 이해하기위해 분석을 수행한다.\nViT의 첫번째 layer는 flatten patch를 더 낮은 차원의 space에 projection한다.</p>\n<p>그림7 왼쪽은 학습된 embedding filter의 구성요소를 보여준다.\n구성요소는 각 patch내 미세 구조의 low-dimensional representation에서 그럴듯한 basic function과 유사하다.</p>\n<p>Projection 이후 학습된 position embedding이 patch representation에 추가된다.\n그림7 가운데는 모델이 position embedding의 유사성에서 이미지 내 거리를 encoding하는 방법을 학습함을 보여준다.<br>\n즉, 더 가까운 patch는 더 유사한 position embedding을 갖는 경향이 있으며 행-열 구조가 나타난다.</p>\n<p>Self-attention을 통해 ViT는 가장 낮은 layer에서도 전체 이미지에 대한 정보를 통합할 수 있다.\nSelf-attention의 weight를 기반으로 정보가 통합되는 이미지 공간의 평균 거리를 계산한다.(그림7 오른쪽)<br>\n“attention distance”는 CNN의 receptive field size와 유사하다.</p>\n<p>일부 head는 이미 최하위 layer에 있는 대부분의 이미지에 attention을 하여 global하게 모델에서 사용됨을 보여준다.\n또한 network 깊이에 따라 attention distance가 증가한다.\n모델이 의미상의 분류와 관련된 이미지 영역을 담당한다는 것을 알 수 있다.(그림6)</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 267px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 198.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig6\"\n        title=\"fig6\"\n        src=\"/static/2dfe41805dc4807c9281de7c1f35ba8d/19e8f/fig6.png\"\n        srcset=\"/static/2dfe41805dc4807c9281de7c1f35ba8d/12f09/fig6.png 148w,\n/static/2dfe41805dc4807c9281de7c1f35ba8d/19e8f/fig6.png 267w\"\n        sizes=\"(max-width: 267px) 100vw, 267px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h2 id=\"46-self-supervision\" style=\"position:relative;\"><a href=\"#46-self-supervision\" aria-label=\"46 self supervision permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.6 Self-supervision</h2>\n<p>Transformer는 NLP task에서 인상적인 성능을 보여주었다.\n그러나 대부분의 성공은 확장성뿐만 아니라 self-supervised pre-training에서 비롯된다.\n또한 BERT에서 사용되는 MLM(Masked Language Modeling)을 모방하여 self-supervision을 위한 Masked Patch Prediction에 대한 예비탐색을 수행한다.</p>\n<p>Self-supervised pre-training을 수행한 ViT-B/16 모델은 ImageNet에서 79.9%의 정확도를 달성하여 scratch로 부터 train을 수행한것보다 2%가 향상되었지만 supervised pre-training보다는 4% 떨어졌다.</p>\n<p>자세한 내용은 Appendix B.1.2에 있으며 contrastive pre-training에 대한 탐구는 future work으로 남김.</p>\n<h1 id=\"5-conclusion\" style=\"position:relative;\"><a href=\"#5-conclusion\" aria-label=\"5 conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Conclusion</h1>\n<p>Image recognition에서 Transformer를 직접 적용하는 방법을 제안했다.\nComputer Vision에서 Self-attention을 사용하는 이전 연구들과 달리, 본 논문에서는 architecture에 image-specific inductive bias를 사용하지 않았다.\n대신 이미지를 patch로 해석하고 NLP에서 사용되는 standard transformer encoder로 처리한다.<br>\n간단하면서도 확장가능한 전략은 large-scale dataset에 대한 pre-train과 결합될 때 놀랍도록 잘 작동하였다.\n따라서 Vision Transformer는 많은 image classification dataset에서 SotA를 능가하거나 능가하는 동시에 pre-train 비용이 상대적으로 저렴하다.</p>\n<p>이러한 결과는 고무적이지만 많은 challenge가 남아있다.<br>\n첫째, dctection 및 segmentation과 같은 computer vision task에 ViT를 적용하는 것이다.<br>\n둘째, pre-training method에 대해 연구하는 것이다.\n초기 실험에서 self-supervised pre-training이 개선된점을 보여주었지만, supervised pre-training을 능가하지만 못하였다.<br>\n셋째, 모델의 크기가 증가하여도 “saturate”상태가 아닌것으로 보이기 때문에 ViT를 더 확장한다.</p>\n<h1 id=\"appendix\" style=\"position:relative;\"><a href=\"#appendix\" aria-label=\"appendix permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Appendix</h1>\n<h2 id=\"b-experiment-details\" style=\"position:relative;\"><a href=\"#b-experiment-details\" aria-label=\"b experiment details permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>B. Experiment details</h2>\n<h3 id=\"b12-self-supervision\" style=\"position:relative;\"><a href=\"#b12-self-supervision\" aria-label=\"b12 self supervision permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>B.1.2 Self-supervision</h3>\n<p>Self-supervision experiment를 위해 Masked Patch Prediction을 사용한다.\n이를 위해 embedding을 학습가능한 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>M</mi><mi>A</mi><mi>S</mi><mi>K</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[MASK]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault\">A</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">K</span><span class=\"mclose\">]</span></span></span></span> embedding(80%), 임의의 다른 patch embedding(10%), 그대로 유지(10%)하여 patch embedding의 50%를 corrupt한다.<br>\n마지막으로 각각의 patch representation을 사용하여 모든 corrupted patch의 3-bit mean color(총 512 color)를 예측한다.</p>\n<p>JFT에서 batch size가 4096인 1M step(약 14epochs)에 대해 self-supervised learning을 수행했다.\n다음과 같이 총 3가지 설정으로 실험을 수행하였으며 1번의 세팅이 가장 좋았다.</p>\n<ol>\n<li>3-bit color 예측</li>\n<li>16x16 patch의 4x4 축소 버전 예측</li>\n<li>L2를 사용한 전체 patch에 대한 regression</li>\n</ol>\n<p>BERT와 같이 corruption rate 15%도 사용하였지만 약간 더 나빳다.</p>\n<h2 id=\"c-additional-analysis\" style=\"position:relative;\"><a href=\"#c-additional-analysis\" aria-label=\"c additional analysis permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>C. Additional Analysis</h2>\n<h3 id=\"c6-attention-distance\" style=\"position:relative;\"><a href=\"#c6-attention-distance\" aria-label=\"c6 attention distance permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>C.6 Attention Distance</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 62.16216216216216%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABxUlEQVQoz21Ta5OiMBD0//83FXRrrfKTVSiwvJOQhAChdyaKh3eXqjGPDj09PXG3LAt4OOdgrcVAszEGTdOEPZ8PRmN84bwvqwpt14U7fH8YBszzHHh2K6FUClobOCNhpUSZ5/jJM/RtA9HU6LWGoXMnarTZHcXjDlFXKGndtTXGcXwS8s80Tago62ANjBbI0gSCiDxh3k/hMqvTskOdZsjyFG6wYDGL96Ru+pewLEuIjkqpS/SyxXashFWRU+KCLLHhfK1unn2w4lMhESohUGUFZqs/PmCcfS2odMtkrGyDe/8fwqIoYXoNq9WbbI21YVL1obwtxsHfO7cp2S8ekgxXSoYPtqMm4x+PRyB1bsDfoxNdwJn0o8vcekkls1+8ZkUcomvR0RNhwr7vn89oixMh4x9NWUvkt8SZmroOXW/b9p35aT7jYzhfcU6wigqEit4fZ7ZkOhvPe0VemdeesT+hgipe69cZq9X0RgVVx/Puer0iiiJExyPi0wmnV+z3e0RxjDiOwv5I+PGwx+n8hQNhX+cz3TkE7HK5EHbA9/cFuyzLgqlJkoDXt9sNaZq+5+R+D0qeinVQwbF2nitilUP4W474BbEXm0ooO2koAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig10\"\n        title=\"fig10\"\n        src=\"/static/aa19bfb5d06d2d9b78feeec87fee492f/fcda8/fig10.png\"\n        srcset=\"/static/aa19bfb5d06d2d9b78feeec87fee492f/12f09/fig10.png 148w,\n/static/aa19bfb5d06d2d9b78feeec87fee492f/e4a3f/fig10.png 295w,\n/static/aa19bfb5d06d2d9b78feeec87fee492f/fcda8/fig10.png 590w,\n/static/aa19bfb5d06d2d9b78feeec87fee492f/5b481/fig10.png 846w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>ViT가 Self-attention을 사용하여 이미지 전체에 정보를 통합하는 방법을 이해하기 위해 각 layer에서 self-attention weight에 따른 average distance를 분석했다. (그림 10)<br>\n“Attention distance”는 하위 layer의 head에서 매우 다양하며 일부 head는 이미지의 많은 부분에 attention하고 일부 head는 근처 작은 영역에 attention한다.<br>\n깊이가 증가하면 모든 head의 attention distance가 증가한다.\nNetwork의 후반부에서 대부분의 head는 token 전반에 걸쳐 widely하게 attention한다.</p>\n<h3 id=\"c7-attention-map\" style=\"position:relative;\"><a href=\"#c7-attention-map\" aria-label=\"c7 attention map permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>C.7 Attention Map</h3>\n<p>Output token에서 input space로의 attention map을 계산하기 위해 Attention Rollout(<a href=\"https://arxiv.org/abs/2005.00928\">Abnar &#x26; Zuidema, 2020</a>)을 사용했다.<br>\n모든 head에서 ViT-L/16의 attention weight를 평균하고 다음 모든 layer의 weight matrix를 반복적으로 곱함.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 563px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 135.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,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'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig13\"\n        title=\"fig13\"\n        src=\"/static/e6ffb9bc4c38fd61890299118c311279/7cb89/fig13.png\"\n        srcset=\"/static/e6ffb9bc4c38fd61890299118c311279/12f09/fig13.png 148w,\n/static/e6ffb9bc4c38fd61890299118c311279/e4a3f/fig13.png 295w,\n/static/e6ffb9bc4c38fd61890299118c311279/7cb89/fig13.png 563w\"\n        sizes=\"(max-width: 563px) 100vw, 563px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>","frontmatter":{"title":"[논문리뷰] An Image is Worth 16X16 Words: Transformers for Image Recognition at Scale","date":"October 13, 2020"}}},"pageContext":{"slug":"/vision/vit/","previous":{"fields":{"slug":"/NLP/rag/"},"frontmatter":{"title":"[논문리뷰] Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks","category":"NLP","draft":false}},"next":{"fields":{"slug":"/NLP/lamda/"},"frontmatter":{"title":"[논문리뷰] LaMDA: Language Models for Dialog Applications","category":"NLP","draft":false}}}},"staticQueryHashes":["3128451518","96099027"]}