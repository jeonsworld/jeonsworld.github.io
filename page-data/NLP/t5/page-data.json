{"componentChunkName":"component---src-templates-blog-post-js","path":"/NLP/t5/","result":{"data":{"site":{"siteMetadata":{"title":"Deep Learner","author":"[Jeonsworld]","siteUrl":"https:jeonsworld.github.io","comment":{"disqusShortName":"","utterances":"jeonsworld/blog-comment"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"897a3579-25d7-508b-92a5-c78bd4bc96f7","excerpt":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu https://arxiv.org/abs/1910.10683 Short Summary unified text-to-text model…","html":"<blockquote>\n<p><strong>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</strong><br>\nColin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu<br>\n<a href=\"https://arxiv.org/abs/1910.10683\">https://arxiv.org/abs/1910.10683</a></p>\n</blockquote>\n<h1 id=\"short-summary\" style=\"position:relative;\"><a href=\"#short-summary\" aria-label=\"short summary permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Short Summary</h1>\n<ul>\n<li><strong>unified text-to-text model을 사용하여 NLP task에서 transfer learning에 대한 체계적인 연구를 수행하여 GLUE, SuperGLUE, CNN/DM 및 SQuAD에서 SotA를 달성</strong></li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 52.02702702702703%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAKABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAIBAwX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHWtViRg//EABgQAQADAQAAAAAAAAAAAAAAAAEAETEh/9oACAEBAAEFAnewunSE/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAFRABAQAAAAAAAAAAAAAAAAAAIDH/2gAIAQEABj8Ci//EABoQAAIDAQEAAAAAAAAAAAAAAAABESExgVH/2gAIAQEAAT8hRzhjFPng+inpoJRg/9oADAMBAAIAAwAAABADz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABoQAQEBAQADAAAAAAAAAAAAAAERACFBkaH/2gAIAQEAAT8QuIh5JMxzxOCHtggRHmN92BNDEOCd3//Z'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"image\"\n        title=\"image\"\n        src=\"/static/6a35e8e37b2c490068cce2537ec96388/1c72d/img1.jpg\"\n        srcset=\"/static/6a35e8e37b2c490068cce2537ec96388/a80bd/img1.jpg 148w,\n/static/6a35e8e37b2c490068cce2537ec96388/1c91a/img1.jpg 295w,\n/static/6a35e8e37b2c490068cce2537ec96388/1c72d/img1.jpg 590w,\n/static/6a35e8e37b2c490068cce2537ec96388/a8a14/img1.jpg 885w,\n/static/6a35e8e37b2c490068cce2537ec96388/fbd2c/img1.jpg 1180w,\n/static/6a35e8e37b2c490068cce2537ec96388/e5166/img1.jpg 1200w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>\n<p>접근방식: 모든 언어문제를 text-to-text task로 변환.</p>\n<ul>\n<li>영어->독일어 번역 예시, input:“translate English to German: That is good.” taget:“Das ist gut.”</li>\n<li>감정분석 예시, input:“sentiment: This movie is terrible!”, target: “negative”</li>\n</ul>\n</li>\n<li>text-to-text 접근방식을 사용하면 동일한 model, loss function, decoding process, training procedure 등을 사용할 수 있음.</li>\n<li>논문의 empirical survey에서 평가한 많은 아이디어에 대한 표준 testbed를 제공.</li>\n<li>pre-train dataset: label이 없는 크롤링 데이터 750GB(“Colossal Clean Crawled Corpus(C4”)</li>\n<li>Tensorflow dataset에서 사용가능 (<a href=\"https://www.tensorflow.org/datasets/catalog/c4\">https://www.tensorflow.org/datasets/catalog/c4</a>)</li>\n<li>논문의 대부분 실험에는 basic encoder-decoder Transformer architecture를 사용.</li>\n<li>text-to-text framework에서 generation, classification task에서 잘 작동하였으며 모델을 Text-to-Text Transfer Transformer”(T5)라고 부른다.</li>\n<li>empirical survey를 위해 encoder-decoder model과 language model을 포함한 다양한 architecture에 대해 비교.</li>\n<li>encoder-decoder architecture는 text-to-text setting에서 가장 잘 수행함.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 74.32432432432432%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAeyaWgf/xAAbEAABBAMAAAAAAAAAAAAAAAARAAECECExQv/aAAgBAQABBQLpiI6Wa//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABYQAQEBAAAAAAAAAAAAAAAAAAEAIP/aAAgBAQAGPwJnP//EABoQAAIDAQEAAAAAAAAAAAAAAAARASExEEH/2gAIAQEAAT8hc5SkeFY2i+LP/9oADAMBAAIAAwAAABDjz//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EABwQAQACAgMBAAAAAAAAAAAAAAEAESFhMUGRcf/aAAgBAQABPxApshRchgVidFTcBli19lbewN/Z/9k='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img2\"\n        title=\"img2\"\n        src=\"/static/ae1d77410d29477dc08b3708992d765f/1c72d/img2.jpg\"\n        srcset=\"/static/ae1d77410d29477dc08b3708992d765f/a80bd/img2.jpg 148w,\n/static/ae1d77410d29477dc08b3708992d765f/1c91a/img2.jpg 295w,\n/static/ae1d77410d29477dc08b3708992d765f/1c72d/img2.jpg 590w,\n/static/ae1d77410d29477dc08b3708992d765f/a8a14/img2.jpg 885w,\n/static/ae1d77410d29477dc08b3708992d765f/fbd2c/img2.jpg 1180w,\n/static/ae1d77410d29477dc08b3708992d765f/e5166/img2.jpg 1200w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></li>\n<li>다음으로 다양한 pre-training objective에 대하여 조사.</li>\n<li>BERT-style의 denoising objective는 일반적으로 다른 접근방식보다 성능이 뛰어나고 SpanBERT-style의 objective는 performance와 training speed의 조합이 가장 뛰어났음을 발견하였음.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.75675675675676%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAduYxUQP/8QAFhABAQEAAAAAAAAAAAAAAAAAEQEg/9oACAEBAAEFAqtc/wD/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAVEAEBAAAAAAAAAAAAAAAAAAAgIf/aAAgBAQAGPwKL/8QAGhAAAwEAAwAAAAAAAAAAAAAAAAERITFRcf/aAAgBAQABPyGy1k7OXwTxaUWoiP/aAAwDAQACAAMAAAAQc8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAbEAEAAwEAAwAAAAAAAAAAAAABABEhMUFR4f/aAAgBAQABPxBoHteOwKi3g72FsLrdlr+Qmh5h6J//2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img3\"\n        title=\"img3\"\n        src=\"/static/3149a792b0375ba0c318dc81e10132d9/1c72d/img3.jpg\"\n        srcset=\"/static/3149a792b0375ba0c318dc81e10132d9/a80bd/img3.jpg 148w,\n/static/3149a792b0375ba0c318dc81e10132d9/1c91a/img3.jpg 295w,\n/static/3149a792b0375ba0c318dc81e10132d9/1c72d/img3.jpg 590w,\n/static/3149a792b0375ba0c318dc81e10132d9/a8a14/img3.jpg 885w,\n/static/3149a792b0375ba0c318dc81e10132d9/fbd2c/img3.jpg 1180w,\n/static/3149a792b0375ba0c318dc81e10132d9/e5166/img3.jpg 1200w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>다양한 unlabeled dataset를 비교하였고 일부의 경우 domain내 pre-train data가 downstream task에서 성능을 향상시키는 것을 발견.</li>\n<li>그러나 C4 dataset는 매우크기 때문에 detrimental(해로운)할 수 있다.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 55.4054054054054%; position: relative; bottom: 0; left: 0; background-image: url('data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAMBAgX/xAAUAQEAAAAAAAAAAAAAAAAAAAAA/9oADAMBAAIQAxAAAAHehVxgsP/EABUQAQEAAAAAAAAAAAAAAAAAAAEg/9oACAEBAAEFAmv/xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAUEAEAAAAAAAAAAAAAAAAAAAAg/9oACAEBAAY/Al//xAAYEAADAQEAAAAAAAAAAAAAAAAAAREQYf/aAAgBAQABPyELjykIf//aAAwDAQACAAMAAAAQE8//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/ED//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/ED//xAAcEAACAgIDAAAAAAAAAAAAAAABEQBhEJFBUXH/2gAIAQEAAT8QB8kCo6RF4MEu4AvcS9z/2Q=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"img4\"\n        title=\"img4\"\n        src=\"/static/fbfe0ca5e295d85998f33ec833ce5bb8/1c72d/img4.jpg\"\n        srcset=\"/static/fbfe0ca5e295d85998f33ec833ce5bb8/a80bd/img4.jpg 148w,\n/static/fbfe0ca5e295d85998f33ec833ce5bb8/1c91a/img4.jpg 295w,\n/static/fbfe0ca5e295d85998f33ec833ce5bb8/1c72d/img4.jpg 590w,\n/static/fbfe0ca5e295d85998f33ec833ce5bb8/a8a14/img4.jpg 885w,\n/static/fbfe0ca5e295d85998f33ec833ce5bb8/fbd2c/img4.jpg 1180w,\n/static/fbfe0ca5e295d85998f33ec833ce5bb8/85367/img4.jpg 1183w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></li>\n<li>unsupervised pre-training은 표준적인 관행이지만 이 방식과 다른 대안은 MT-DNN과 같이 supervised, unsupervised data의 혼합 dataset을 pre-training하는것이다.</li>\n<li>mixing proportions(혼합 비율)이 맞으면 두 가지 방법 모두 비슷한 성능을 달성할 수 있음.</li>\n<li>scaling up은 성능을 향상시키는 강력한 방법이지만 어떻게 확장해야 하나?</li>\n<li>더 많은 data에 대한 training, 더 긴(오래) model training, 특정 computational budget(계산비용 or 계산예산)에 따라 training을 비교하였음.</li>\n<li>TL;DR 결론적으로 많은 data, training a longer model 모두 성능을 향상시킴.</li>\n<li>연구에서 얻은 통찰력을 통해 1조개의 data token에 대해 다양한 크기의 5가지 model을 training.(최대 110억개의 parameter)</li>\n<li>GLUE, SuperGLUE, SQuAD 및 CNN/DM에서 SotA를 얻었지만 WMT Translation을 얻지못함.</li>\n<li>SuperGLUE의 경우 이전 SotA보다 4.3%를 향상시켰으며 human performance의 범위내에 있다.(88.9 vs 89.8)</li>\n<li>SuperGLUE는 사람에게는 쉽지만 machine에게는 어려운 task만 포함하도록 설계되었다.</li>\n</ul>","frontmatter":{"title":"[논문리뷰] Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer","date":"October 04, 2019"}}},"pageContext":{"slug":"/NLP/t5/","previous":{"fields":{"slug":"/NLP/lama/"},"frontmatter":{"title":"[논문리뷰] Language Models as Knowledge Bases?","category":"NLP","draft":false}},"next":{"fields":{"slug":"/NLP/plato/"},"frontmatter":{"title":"[논문리뷰] PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable","category":"NLP","draft":false}}}},"staticQueryHashes":["3128451518","96099027"]}