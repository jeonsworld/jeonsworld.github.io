{"componentChunkName":"component---src-templates-blog-post-js","path":"/NLP/albert/","result":{"data":{"site":{"siteMetadata":{"title":"Deep Learner","author":"[Jeonsworld]","siteUrl":"https:jeonsworld.github.io","comment":{"disqusShortName":"","utterances":"jeonsworld/blog-comment"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"20a071df-d7b0-5e42-826a-122c2502a943","excerpt":"ALBERT: A Lite BERT for Self-supervised Learning of Language Representations Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut https://arxiv.org/abs/1909.11942 1. Introduction full-network pre-training(Radford et al., 2018; Devlin et al…","html":"<blockquote>\n<p><strong>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</strong><br>\nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut<br>\n<a href=\"https://arxiv.org/abs/1909.11942\">https://arxiv.org/abs/1909.11942</a></p>\n</blockquote>\n<h1 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Introduction</h1>\n<p>full-network pre-training(Radford et al., 2018; Devlin et al., 2019)은 language representation learning에서 큰 발전을 이뤘다.\n가장 큰 발전은 RACE test(Lai et al., 2017)의 성능을 많이 개선한것.</p>\n<ul>\n<li>RACE test paper기준 baseline 44.1%.</li>\n<li>ALBERT는 89.4%를 달성하여 +45.3%를 개선.</li>\n</ul>\n<p>network 성능을 개선하기위해 <strong>large network를 training하고 더 작은 model로 distill하는것이 일반적인 관행</strong>이 되었다.\nNLP task의 성능을 높이는 쉬운 방법이 더 큰 모델을 사용하는 것인가?</p>\n<p>large network를 train함에 있어 memory limitation problem이 있고, communication overhead는 parameter 갯수에 의존하므로 distributed training에서는 속도가 크게 저하될 수 있다.\n또한 BERT-large를 단순하게 hideen size만 증가시키면 성능이 저하 될 수 있다.\n그림1과 표1은 BERT-large의 hidden size를 2배로 늘리고 BERT-xlarge가 더 나쁜 결과를 얻는 예시를 보여줌.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 42.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABgUlEQVQoz1VSCZKjMAzk//+brRyEZIAshGAuX8SG9EoiQ+2oSmWQ2m2ppSSEAO89Xq8X5nkW9+TOOYnHGPFjjAmBcHQ6/8ERxlonObbETBOGVuH9fmNZFsQQMQ4TrtcryvIuxGzWGnR9D21nyhsMvRYfB42+G6G12Qir+oG2UfhtRL6u8gBXydapFvf6CW883hRnDFWx3+DOhLD8W+FRPQFqJSzrRrdExHlr4YdwGAYUZQ2sC1NJR//bTuicRUct9EqjLp9oK4XqTv5dY1IjrLECHKcReV79qirEFS3JpZTapUnm2WMiHa3zcFqjI0DfDzDGYBrGvcKFqm4ezT4srVnDHnVdk9al4IVwJa14QjEGOfk1Tm4TDTJl1nL9aMqxILiWCtFbTO5vmCQvChR5jsPhgDS9UFu5+Dd5ll0odkZBmCzL5J/P8/kk8dvthsslw5+vL4qd0TQNkuPxKESn03amafq5fJXV4Ty3xK2OI60HVW+MpjWymywsF32zBJ528x9vlrJGVR3xyAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig1\"\n        title=\"fig1\"\n        src=\"/static/ba844376236de145cf9929b6a83b04a1/fcda8/fig1.png\"\n        srcset=\"/static/ba844376236de145cf9929b6a83b04a1/12f09/fig1.png 148w,\n/static/ba844376236de145cf9929b6a83b04a1/e4a3f/fig1.png 295w,\n/static/ba844376236de145cf9929b6a83b04a1/fcda8/fig1.png 590w,\n/static/ba844376236de145cf9929b6a83b04a1/6af66/fig1.png 640w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 550px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 20.945945945945947%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA1UlEQVQY0zVQy46DMAzk/z9p+wNdCThRDi2FEpLlHUh4XBCZxu52JEeWPTO2E8BDCIH744Ft22CtgbEWy7Jgnmf0Xcu9oii4nuc5sizjnhAlXq+Se1pPZIWAnjiOcbn8IIwiRD6y5xNVVbGwrmukaYokSbDvO9Jbguv1F8YY6HFEGIbMs36Yc+5j2HUdyvIzTUqJdV3xxXEcfrrG6MWEeZqglOLcuRN93/NlhPM8ETR+g8EXSUTbUJB50zRMphPpS9q2hZIVRs+j+p83lUoybxiG/7M13sA7KdXt+Z2QAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table1\"\n        title=\"table1\"\n        src=\"/static/3c44ab0d88db8fee461517566055d3d7/dd45a/table1.png\"\n        srcset=\"/static/3c44ab0d88db8fee461517566055d3d7/12f09/table1.png 148w,\n/static/3c44ab0d88db8fee461517566055d3d7/e4a3f/table1.png 295w,\n/static/3c44ab0d88db8fee461517566055d3d7/dd45a/table1.png 550w\"\n        sizes=\"(max-width: 550px) 100vw, 550px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>앞에서 제시한 문제에 대한 solution은 model parallelization(Shoeybi et al., 2019) 및 clever memory management(Chen et al., 2016; Gomez et al., 2017)가 있다.\n그러나 이 solution들은 memory limitation problem은 해결하지만 communication overhead 및 model degradation problem은 해결하지 못한다.  </p>\n<p>본 논문에서는 ALBERT architecture를 제안하여 위의 문제들을 모두 해결함.</p>\n<ul>\n<li>\n<p>ALBERT에서 제안하는 두 가지 prameter reduction technic:</p>\n<ol>\n<li><strong>factorized embedding parameterization</strong>: large vocabulrary embedding matrix를 두 개의 small matrices로 분리.</li>\n<li><strong>cross-layer parameter sharing</strong>: network depth에 따라 parameter가 커지는 것을 방지.  </li>\n</ol>\n</li>\n</ul>\n<p>두 개의 technic 모두 성능을 크게 저하시키지 않으면서 BERT의 parameter를 크게 reduction하여 parameter-efficiency를 향상.\nBERT-large와 유사한 ALBERT의 configuration은 parameter가 18배 적으며 약 1.7배 더 빠르게 train.\nparameter reduction technic은 training을 안정화 시키고 일반화를 돕는 정규화의 형태로도 작용 함.</p>\n<p>ALBERT의 성능을 더욱 향상시키기 위해 <strong>SOP(Sentence-Order Prediction)</strong>에 대한 self-supervised loss 제안.\nSOP는 inter-sentence coherence(일관성)에 중점을 두고 있으며 NSP(Next Sentence Prediction) ineffectiveness를 개선하도록 설계.</p>\n<p>이러한 설계를 통해 BERT를 ALBERT로 확장시켜 GLUE, SQuAD, RACE benchmark에서 SotA를 달성.</p>\n<h1 id=\"2-related-work\" style=\"position:relative;\"><a href=\"#2-related-work\" aria-label=\"2 related work permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Related Work</h1>\n<h2 id=\"21-scaling-up-representation-learning-for-natural-language\" style=\"position:relative;\"><a href=\"#21-scaling-up-representation-learning-for-natural-language\" aria-label=\"21 scaling up representation learning for natural language permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 Scaling up Representation Learning for Natural Language</h2>\n<p>Devlin et al. (2019)는 더 큰 hidden size, hidden layer, attention head를 사용하면 더 나은 성능을 보여줄 수 있음을 확인할 수 있었다.\n그러나 1024 hidden size까지만 확인을 했으며 2048로 늘리면 오히려 성능이 저하되는 것을 확인할 수 있었다.\n따라서 natural language에 대한 representation learning을 확장하는 것은 model size를 늘리는 것만큼 단순하지는 않다.  </p>\n<p>또한 GPU / TPU의 메모리는 제한적이고 최신 모델들은 수억 또는 수십억 개의 parameter를 가지므로 memory limitation problem이 쉽게 발생한다.\n이 문제를 해결하기 위해 Chen et al. (2016)은 gradient checkpointing이라는 방법을 제안하였고 Gomez et al. (2017)은 각 layer의 activation을 재구성하여 intermediate activation을 저장할 필요가 없도록 하는 방법을 제안하였다.\n두 방법 모두 속도비용으로 메모리 메모리 소비를 줄인다.\n반대로, parameter reduction techniques는 메모리 소비를 줄이고 학습 속도를 높인다.</p>\n<h2 id=\"22-cross-layer-parameter-sharing\" style=\"position:relative;\"><a href=\"#22-cross-layer-parameter-sharing\" aria-label=\"22 cross layer parameter sharing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.2 Cross-Layer Parameter Sharing</h2>\n<p>Dehghani et al., (2018)에 따르면 cross-layer parameter sharing이 있는 network는 standard transformer보다 language modeling 및 subject-verb agreement task에서 더 나은 성능을 보여줬음.  </p>\n<p>Bai et al., (2019)는 transformer network를 위한 DQE(Deep Equilibrium model)을 제안하고 DQE가 특정 layer의 input embedding과 output embedding이 동일하게 유지되는 equilibrium point(평형점) 도달할 수 있음을 보여주었음.저자들의 관찰에 따르면 BERT의 embedding이 수렴하기 보다는 진동하고 있음.  </p>\n<p>Hao et al., (2019)는 parameter-sharing transformer를 standard transformer와 결합하여 standard transformer보다 더 높은 성능을 달성.</p>\n<h2 id=\"23-sentence-ordering-objectives\" style=\"position:relative;\"><a href=\"#23-sentence-ordering-objectives\" aria-label=\"23 sentence ordering objectives permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3 Sentence Ordering Objectives</h2>\n<ul>\n<li>ALBERT는 두 개의 text segment의 순서를 예측하여 pre-train loss로 사용한다.</li>\n<li>BERT에서 사용하는 NSP는 SOP와 비교하여 더 쉬운 task.</li>\n<li>NSP loss는 single task에서 topic prediction과 coherence prediction을 수행하는데 topic prediction은 coherence prediction에 비해 쉬운 task이고 MLM loss를 사용하여 학습한 내용과 겹치게 됨.</li>\n<li>SOP는 특정 downstream task에서 더 효과적임을 알아냈음.</li>\n</ul>\n<h1 id=\"3-the-elements-of-albert\" style=\"position:relative;\"><a href=\"#3-the-elements-of-albert\" aria-label=\"3 the elements of albert permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. The Elements of ALBERT</h1>\n<h2 id=\"31-model-architecture-choices\" style=\"position:relative;\"><a href=\"#31-model-architecture-choices\" aria-label=\"31 model architecture choices permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1 Model Architecture Choices</h2>\n<ul>\n<li>ALBERT architecture의 backbone은 transformer encoder와 GLEU activation function을 사용한다는 점에서 BERT와 유사함.</li>\n<li>\n<p><strong>Factorized embedding parameterization</strong></p>\n<ul>\n<li>modeling 관점에서 Wordpiece embedding은 context-independent representation을 배우고 hidden-layer embedding은 context-dependent representation을 배운다.</li>\n<li>자연어 처리는 일반적으로 vocabulary size <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>V</mi></mrow><annotation encoding=\"application/x-tex\">V</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span></span></span></span>가 클수록 좋다.</li>\n<li>이로 인해 수십억개의 parameter가 있는 model이 쉽게 생성될 수 있으며, 대부분은 training에서 드물게 업데이트 된다.</li>\n<li>ALBERT는 embedding parameter를 factorization하여 두 개의 작은 matrices로 분해한다.</li>\n<li><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mrow><mo fence=\"true\">(</mo><mi>V</mi><mo>×</mo><mi>X</mi><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">O\\left( V\\times X \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.07847em;\">X</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span> -> <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>O</mi><mrow><mo fence=\"true\">(</mo><mi>V</mi><mo>×</mo><mi>E</mi><mo>+</mo><mi>E</mi><mo>×</mo><mi>H</mi><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">O\\left( V\\times E+E\\times H \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathdefault\" style=\"margin-right:0.22222em;\">V</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></li>\n<li>parameter reduction은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>H</mi><mo>≫</mo><mi>E</mi></mrow><annotation encoding=\"application/x-tex\">H\\gg E</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.08125em;\">H</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">≫</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span></span></span>일 때 의미가 있다.</li>\n</ul>\n</li>\n<li>\n<p><strong>Cross-layer parameter sharing</strong></p>\n<ul>\n<li>parameter sharing 방법(only sharing feed-forward network (FFN) parameters across layers, or only sharing attention parameters)</li>\n<li>ALBERT의 default decision은 share all parameters across layers.</li>\n<li>이러한 design decision을 Section 4.5에서 실험.</li>\n<li>그림 2는 BERT-large 및 ALBERT-large configuration을 사용하여 각 layer에 대한 input, output embedding의 L2 distance 및 cosine similarity를 보여줌.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.513513513513516%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXUlEQVQoz02S2XKDMAxF+f/fy0smSSF9oAmr8YJt1tsrJ6T14BFYx9KVROacg1YD2rZFVVUYxxEhhLS995jnGbJ88FBdD9X3eDyfMMYgxJg4uTNNU+IyrTUPQgIEFOhYK6Hju2lqdL1ikoBHWcJSyLG2dUV8c1lJZ3xHx77z2bAT2KlsYfYDrBmwqRtmoY9n4t94T+xMhZ+AVV2jLFsEy/JCTHuZGCwSJBT/KcwLKhtGxlyxzCvWbcfGPfHOX8kste00S5thXITzM+wY0/voXz1KAdsO5U+VgmgbyE0fzjj/4TJpujR1WWYEDkGpHj6VIIPxSc2rGzucIyclUo0Mx1lLZTHdO4aXyZQtHdY69ISapk0DkrNhGNB1XXqX4RmjMdBqbVCzVUqpxIgVIY5Csu/7HUVR4H4vcLlccT6fcb1ekec5vm43nE4n3GglkVTy+itGHEKMeSWz1qR+/wJnvGiAsOC7pwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig2\"\n        title=\"fig2\"\n        src=\"/static/d7bee3741a9b7f54195a9756073400d4/fcda8/fig2.png\"\n        srcset=\"/static/d7bee3741a9b7f54195a9756073400d4/12f09/fig2.png 148w,\n/static/d7bee3741a9b7f54195a9756073400d4/e4a3f/fig2.png 295w,\n/static/d7bee3741a9b7f54195a9756073400d4/fcda8/fig2.png 590w,\n/static/d7bee3741a9b7f54195a9756073400d4/e9c9b/fig2.png 627w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></li>\n<li>parameter sharing이 network의 parameter 안정화에 영향을 주는것을 알 수 있음</li>\n</ul>\n</li>\n<li>\n<p><strong>Inter-sentence coherence loss</strong></p>\n<ul>\n<li>BERT는 MLM loss와 NSP loss를 사용한다.</li>\n<li>그러나 후속연구(Yang et al., 2019; Liu et al., 2019)는 NSP의 영향을 신뢰할 수 없으며 이를 제거한다.</li>\n<li>NSP의 ineffectiveness의 주된 이유는 MLM과 비교할 때 쉬운 task이기 때문이라고 추측한다.</li>\n<li>이를 개선하기 위해 SOP loss를 사용하여 문장간 일관성을 모델링함.</li>\n<li>SOP loss는 동일한 document에서 두 개의 연속 segment를 positive sample로 사용, 두 개의 segment의 순서가 바뀐것은 negative sample로 사용한다.</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"32-model-setup\" style=\"position:relative;\"><a href=\"#32-model-setup\" aria-label=\"32 model setup permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.2 Model setup</h2>\n<p>표2에서 비슷한 hyper-parameter setting을 사용하여 BERT와 ALBERT의 차이점을 설명. 앞에서 설명한 설계 선택으로 인해 ALBERT의 model은 해당되는 BERT model에 비해 parameter size가 훨씬 작음.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 585px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 29.054054054054056%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABJ0lEQVQY0zVR23KCQAzl//+svlinqHUGKCywQrXAggt4wdOTtGZmB5JNziUbPJ9PXIYBxuQYxwnX6xVFUejpug51XfPbIsuM5mVZIjMGTdvqvxzpbZoGEkFdVzr083PGfv9J0BFRFOFttcI8TcjzHN57bDYb9CS2ZYFwu8PtdkPf93hfr2GPR81FXDCwaZ5n+MuAMAzJ1OrQR7jVelVV8CTZ73aQ3tN3jThOFEDcHA4HimnweDz+AJ3raCdTyWma6nBFxiRJtEHUC7Dk3o9wtH3k/bIsWAhiaL9zTnMFFN/3+10vY1p1/YCBVmQvErICiYxkCwdEmSPAK8TBxNW8Iiitxfl0IqullVjVWtYkL7i/OI7wlWZUbRHxXlyY/x55yNejSL2nmF9XpMOZXM8XeAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table2\"\n        title=\"table2\"\n        src=\"/static/74659159a4a5067cdd90b187d1714fe9/78a22/table2.png\"\n        srcset=\"/static/74659159a4a5067cdd90b187d1714fe9/12f09/table2.png 148w,\n/static/74659159a4a5067cdd90b187d1714fe9/e4a3f/table2.png 295w,\n/static/74659159a4a5067cdd90b187d1714fe9/78a22/table2.png 585w\"\n        sizes=\"(max-width: 585px) 100vw, 585px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>예시로, ALBERT-large는 BERT-large에 비해 18배 더 적은 parameter(18M, 334M).</li>\n<li>이러한 parameter efficiency 개선은 ALBERT의 설계 선택에서 가장 중요한 이점이다.</li>\n<li>이 장점을 정량화하기 전에 실험 설정을 보다 자세하게 소개함.</li>\n</ul>\n<h1 id=\"4-experimental-results\" style=\"position:relative;\"><a href=\"#4-experimental-results\" aria-label=\"4 experimental results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Experimental Results</h1>\n<h2 id=\"41-experimental-setup\" style=\"position:relative;\"><a href=\"#41-experimental-setup\" aria-label=\"41 experimental setup permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.1 Experimental Setup</h2>\n<ul>\n<li>Pre-train corpora: BookCorpus, Wikipedia (약 16GB)</li>\n<li>BERT와 동일한 input format: <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">[</mo><mi>C</mi><mi>L</mi><mi>S</mi><mo stretchy=\"false\">]</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy=\"false\">[</mo><mi>S</mi><mi>E</mi><mi>P</mi><mo stretchy=\"false\">]</mo><msub><mi>x</mi><mn>2</mn></msub><mo stretchy=\"false\">[</mo><mi>S</mi><mi>E</mi><mi>P</mi><mo stretchy=\"false\">]</mo></mrow><annotation encoding=\"application/x-tex\">[CLS]{ x }_{ 1 }[SEP]{ x }_{ 2 }[SEP]</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.07153em;\">C</span><span class=\"mord mathdefault\">L</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mclose\">]</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">]</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\">x</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mopen\">[</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span><span class=\"mclose\">]</span></span></span></span></li>\n<li>maximum input length:512 10% 확률로 512보다 짧은 input sequence를 random하게 생성.</li>\n<li>Wordpiece vocab size: 30,000 (BERT, XLNet)</li>\n<li>n-gram masking을 사용하며 각 n-gram masking의 길이를 random하게 선택. 길이 n의 확률은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>p</mi><mrow><mo fence=\"true\">(</mo><mi>n</mi><mo fence=\"true\">)</mo></mrow><mo>=</mo><mfrac><mrow><mn>1</mn><mi mathvariant=\"normal\">/</mi><mi>n</mi></mrow><mrow><msubsup><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></msubsup><mrow><mn>1</mn><mi mathvariant=\"normal\">/</mi><mi>k</mi></mrow></mrow></mfrac></mrow><annotation encoding=\"application/x-tex\">p\\left( n \\right) =\\frac { 1/n }{ \\sum _{ k=1 }^{ N }{ 1/k }  }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">p</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord mathdefault\">n</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.664672em;vertical-align:-0.654672em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.01em;\"><span style=\"top:-2.570335em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mop mtight\"><span class=\"mop op-symbol small-op mtight\" style=\"position:relative;top:-0.0000050000000000050004em;\">∑</span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8852357142857143em;\"><span style=\"top:-2.1785614285714283em;margin-left:0em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-2.8971428571428572em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">N</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32143857142857146em;\"><span></span></span></span></span></span></span><span class=\"mspace mtight\" style=\"margin-right:0.19516666666666668em;\"></span><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">/</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03148em;\">k</span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.485em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span><span class=\"mord mtight\">/</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.654672em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></li>\n<li>n-gram 최대 길이: 3</li>\n<li>batch size: 4096</li>\n<li>optimizer: Lamb(You et al., 2019)</li>\n<li>learning rate: 0.00176</li>\n<li>Cloud TPU v3에서 진행하였으며 사용된 TPU의 수는 model size에 따라 64~1024</li>\n</ul>\n<h2 id=\"43-overall-comparison-between-bert-and-albert\" style=\"position:relative;\"><a href=\"#43-overall-comparison-between-bert-and-albert\" aria-label=\"43 overall comparison between bert and albert permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.3 Overall Comparison between BERT and ALBERT</h2>\n<ul>\n<li>ALBERT-xxlarge는 표3과 같이 ALBERT 설계 선택의 가장 중요한 이점을 보여줌.</li>\n<li>BERT-large parameter의 약 70%만으로 ALBERT-xxlarge는 개발 차이에 의해 측정된 BERT-large보다 크게 개선되었음.(SQuAD v1.1 (+1.7%), SQuAD v2.0 (+4.2%), MNLI (+2.2%), SST-2 (+3.0%), and RACE (+8.5%))</li>\n<li>또한 BERT-xlarge는 모든 metric에서 BERT보다 낮은 성능을 보여줌</li>\n<li>이는 BERT-xlarge와 같은 model이 더 작은 parameter를 가진 model보다 train하기 더 어렵다는 것을 보여줌.</li>\n<li>또 다른 흥미로운 점은 동일한 training configuration(동일한 수의 TPU)에서 training time의 데이터 처리 속도이다.</li>\n<li>통신과 계산이 적기 때문에 ALBERT model은 BERT model에 비해 데이터 처리량이 더 높다.</li>\n<li>예시로 ALBERT-xlarge는 BERT-xlarge보다 2.4배 빠르게 train할 수 있다.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.756756756756754%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABLElEQVQY0y2R2a6DMAxE+f9/Q110y5KFNezQAOqqVpra1n2w4iRkfGYI9m3DMIyY5wlZlmPfdxwPB4zThCSJkaQphr5HGIb03YCiKNDTvus6tG0DYyzyPIera1yvHsHz+cT9/sAyz4iimAQ3XC5/WJYFcRxBGyN3p/NZhMuyhHMONQl0bQtrrYA0TYON4IL3+00TOyKcobUGD+CVz1kwVYomLzgeT/Dei9A4TkK7kCtLYkzN7xkseL1e4GIhtrGuq9DdbjexxpPX1RNZJXcsxCQTCXBMfT/8n614kEbgXA2ltOTA+IqIyqokSgNNvaIM2bah0lpJz2fWGqS0Zpklaif7hiIIvL9K0xNdTdnwNA64bTuyNkpeTMnFdsuqot4JPec50c/7fr/4fD5SP9s1ut/gm/qUAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table3\"\n        title=\"table3\"\n        src=\"/static/4f8a2c876fd81c54bc1956e61981a010/fcda8/table3.png\"\n        srcset=\"/static/4f8a2c876fd81c54bc1956e61981a010/12f09/table3.png 148w,\n/static/4f8a2c876fd81c54bc1956e61981a010/e4a3f/table3.png 295w,\n/static/4f8a2c876fd81c54bc1956e61981a010/fcda8/table3.png 590w,\n/static/4f8a2c876fd81c54bc1956e61981a010/6af66/table3.png 640w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h2 id=\"44-factorized-embedding-parameterization\" style=\"position:relative;\"><a href=\"#44-factorized-embedding-parameterization\" aria-label=\"44 factorized embedding parameterization permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.4 Factorized Embedding Parameterization</h2>\n<ul>\n<li>표4는 대표적인 downstream task에서 ALBERT 기반 configuration을 사용하여(표 2) embedding size를 변경한 결과를 보여줌</li>\n<li>non-shared condition(BERT-style)에서는 embedding size가 클수록 성능이 향상되지만 그다지 크진 않다.</li>\n<li>all-shared condition(ALBERT-style)에서는 128 size가 가장 좋다.</li>\n<li>이러한 결과를 바탕으로 향후 모든 설정에서 embedding size <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>=</mo><mn>128</mn></mrow><annotation encoding=\"application/x-tex\">E=128</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">2</span><span class=\"mord\">8</span></span></span></span>을 사용한다.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 584px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 31.756756756756754%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABN0lEQVQY0yWQyXqDMBCDef8XCzk0IV0SCDjsuwGblP2gzrgHPpuRLf+Sta4L7vc76rpG27aQXYfPm4MkSSGCAOezjbIsIYTAx+VizrmuiyLPzYw1z/PMvigKWGzoXK+oqprEAsu6IQoFBjWioctX0pTSpFdk5GGZZ2M6TROapsE4jmZN0xQdwVjT9Gt+mC4MQzJS+Pn+QpblSOIItm2jIS2KIjiOg05K+L6PlkyYih+K6dzz+aQ7GazjOOA+HkShaJBiXlYI36PoPcXKcDqdDCHHuVBkJovjGMPQ/wMMAxICer04ckmG+46c+tB6NMj7fkC2DSYyVnQpCATWbcP7/SajBBvt2YSrkkQ7UwVaa5OQoSwesMBDKTsTiXvhnvgB/ioqvu97Y8Qrd8YGWivSJTIi5PMr9f8HSBi9NrDDTKQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table4\"\n        title=\"table4\"\n        src=\"/static/9ccf49ce441cbf769b87209ce6ad5da7/e05eb/table4.png\"\n        srcset=\"/static/9ccf49ce441cbf769b87209ce6ad5da7/12f09/table4.png 148w,\n/static/9ccf49ce441cbf769b87209ce6ad5da7/e4a3f/table4.png 295w,\n/static/9ccf49ce441cbf769b87209ce6ad5da7/e05eb/table4.png 584w\"\n        sizes=\"(max-width: 584px) 100vw, 584px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h2 id=\"45-cross-layer-parameter-sharing\" style=\"position:relative;\"><a href=\"#45-cross-layer-parameter-sharing\" aria-label=\"45 cross layer parameter sharing permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.5 Cross-layer parameter sharing</h2>\n<ul>\n<li>표 5는 두가지 embedding size(768, 128)를 가진 ALBERT 기반 configuration(표 2)을 사용하여 cross-layer parameter sharing에 대한 실험을 보여줌.</li>\n<li>all-shared stategy(ALBERT-style), non-shared strategy(BERT-style) 및 only the attention parameter share, FFN parameter share</li>\n<li>all-shared strategy는 두 조건 모두에서 성능을 저하시킨다. 그러나 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>=</mo><mn>768</mn></mrow><annotation encoding=\"application/x-tex\">E=768</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">7</span><span class=\"mord\">6</span><span class=\"mord\">8</span></span></span></span>(Avg에서 -2.5)에 비해 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>=</mo><mn>128</mn></mrow><annotation encoding=\"application/x-tex\">E=128</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">2</span><span class=\"mord\">8</span></span></span></span>(Avg에서 -1.5)에 대해서는 덜 감소한다.</li>\n<li>또한 대부분의 성능 저하는 FFN layer parameter sharing에서 비롯된 것으로 나타났지만 attention parameter를 sharing하면 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>=</mo><mn>128</mn></mrow><annotation encoding=\"application/x-tex\">E=128</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">1</span><span class=\"mord\">2</span><span class=\"mord\">8</span></span></span></span>(Avg에서 +0.1)일 때 하락이 발생하지 않으며 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>E</mi><mo>=</mo><mn>768</mn></mrow><annotation encoding=\"application/x-tex\">E=768</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.68333em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.64444em;vertical-align:0em;\"></span><span class=\"mord\">7</span><span class=\"mord\">6</span><span class=\"mord\">8</span></span></span></span>(Avg에서 -0.7)에서 약간의 하락이 발생한다.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 29.054054054054056%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABK0lEQVQY0z1R6c7CMAzb+78du9nB7nb3CeMDfvhzikSlKkqaOLZrneeJeZoQxzH2fcf7/cbQ94iiCF3XIbpekSQpJvb4noeyqlCWJeq6NlF60jRlXmEcJ1i27WCaZ1w56HFAKYXjuCMm4HEc8H0PQRDi8bjDcWworTGNIzSjZu+yLAZcbtt2sCpulKLnOhDwdduwrivCMMTMRWEQEDBgbSGgg6ZRhpVSmgwLDMOA2+2GsijQsk6GtpHjuS4ul4thIMxE8rbtBPN/gC57ZGgYegOo9ZdhlmUoCDgSxxLfPp8PijxHnCQ4n0+Tiz8mFjlyvr1ef2ZoXTfKf2Dn0p1qjOdk2dP3eV5giXb5hLppIPLlUfxRzL/mN79PECZt2yJnTLhcPBPZIlnskfMP46+6sSetrYsAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table5\"\n        title=\"table5\"\n        src=\"/static/cdc1de04d1689dc43ed7e58332427250/fcda8/table5.png\"\n        srcset=\"/static/cdc1de04d1689dc43ed7e58332427250/12f09/table5.png 148w,\n/static/cdc1de04d1689dc43ed7e58332427250/e4a3f/table5.png 295w,\n/static/cdc1de04d1689dc43ed7e58332427250/fcda8/table5.png 590w,\n/static/cdc1de04d1689dc43ed7e58332427250/b5bda/table5.png 643w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h2 id=\"46-sentence-order-prediction-sop\" style=\"position:relative;\"><a href=\"#46-sentence-order-prediction-sop\" aria-label=\"46 sentence order prediction sop permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.6 Sentence order prediction (SOP)</h2>\n<ul>\n<li>\n<p>ALBERT base configuration을 사용하여 SOP에 대한 세가지 실험을 head-to-head로 비교한다.</p>\n<ol>\n<li>none(XLNet and RoBERTa)</li>\n<li>NSP(BERT)</li>\n<li>SOP(ALBERT)</li>\n</ol>\n</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 20.945945945945947%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAy0lEQVQY0z2P2w6CMBBE+f8/0ycNGoIJV5FK77T6gjTjdhN9mEyy0z07LVLa4b2HX1fMjwfatmXN8wxjDCvGiJXejOOIrutQ1zX6YYBzHivtOecQQkBKCcW2bSjLEkopVFWFaZrQ9z0rg4+HA8On+x2n0xnLsqBpGggh/j4QPB/JrOLz2RiS6VJKvmSplc7SCtfLhVpaaDpY3254v1/8kxhf3N5Zy0cydN+pobWGBpLDDDRas2tyIZ7snBHQ0rKUinOlSJRl2G8WQsQXKBoqIMurAiQAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table6\"\n        title=\"table6\"\n        src=\"/static/6f9e750af0c0513f04188a03c32a5203/fcda8/table6.png\"\n        srcset=\"/static/6f9e750af0c0513f04188a03c32a5203/12f09/table6.png 148w,\n/static/6f9e750af0c0513f04188a03c32a5203/e4a3f/table6.png 295w,\n/static/6f9e750af0c0513f04188a03c32a5203/fcda8/table6.png 590w,\n/static/6f9e750af0c0513f04188a03c32a5203/af590/table6.png 626w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>NSP loss가 SOP task에 이점이 없음을 보여줌.(none과 비슷한 52.0%의 정확도)</li>\n<li>이를 통해 NSP는 topic shift만 modeling한다는 결론을 내릴 수 있음.</li>\n<li>반대로 SOP loss는 NSP task를 잘 해결하고(78.9% 정확도), SOP task도 잘 수행함.(86.5% 정확도)</li>\n<li>더 중요한 점은 SOP loss가 multi-sentence encoding task에서 개선되었다는 점.(+1% for SQuAD1.1, +2% for SQuAD2.0, +1.7% for RACE)</li>\n</ul>\n<h1 id=\"47-effect-of-network-depth-and-width\" style=\"position:relative;\"><a href=\"#47-effect-of-network-depth-and-width\" aria-label=\"47 effect of network depth and width permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.7 Effect of network depth and width</h1>\n<ul>\n<li>depth(number of layers)와 width(hidden size)가 ALBERT의 성능에 미치는 영향에 대해 조사함.</li>\n<li>표 7은 다른 수의 layer를 사용하는 ALBERT-large configuration의 성능을 보여줌.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 27.7027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsTAAALEwEAmpwYAAABLklEQVQY0zVR2XKDMBDj/38nr+kPNLxAM0m4r5ICJpwxV+iou5spMx7La62sFUaWpcjzHN9ZhrZtURYFXM9DVSlkaQLP99F1PeEUjuOgaRqEYQilFJIkoXOLOI5xv9/xQ8vQWgtpGAbM84yh72FZNjXUSOIIpmlKc0z483RCT/dBEKCuH3CdGxTtcRSJuOe6MEDfNGns+84Qv/tLHEzTTC/muF6uhCc86hq+HwivJrysm0wzz4vsimpVWb4FmTyOTxF8bSss2wY7v17OOB4/xJVzu+FwOKDtOhL2qDZIJC3Fwc5SiuT8ZcNYloXERnGxbRvWdRUBGX/oJVfm8M5ZC6aIGjqzI019Wj8lMl4Gh8mgqioUZJ3HKYnIzZwd1951JXec3b8415nLwhn9VMZ/i/O/5t1KxPgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table7\"\n        title=\"table7\"\n        src=\"/static/1d086aefc1bc39799296e0a8848812e5/fcda8/table7.png\"\n        srcset=\"/static/1d086aefc1bc39799296e0a8848812e5/12f09/table7.png 148w,\n/static/1d086aefc1bc39799296e0a8848812e5/e4a3f/table7.png 295w,\n/static/1d086aefc1bc39799296e0a8848812e5/fcda8/table7.png 590w,\n/static/1d086aefc1bc39799296e0a8848812e5/699b7/table7.png 596w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>모두 1-layer ALBERT model과 동일한 parameter를 갖지만 성능이 크게 향상됨.</li>\n<li>그러나 layer수를 계속 늘릴수록 증가의 폭이 줄어듦. 12-layer는 24-layer와 비교적 비슷하며 48-layer는 성능이 저하됨.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 20.27027027027027%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA0klEQVQY0yVQ2Y6DMBDr/3/a9mUrbUGARJeEJg3kAh4Q4vDOzEaK4jhjjyc30DqOA01d4/X6Rc4JRVHgbQyapkZVVfDe4/n8EU4pBWPe6LoOzjnStMLlnNkKt+u6BHw+Flr3gsuyRExJmnw/HljXFff7F3Tfw1qLeZ7Qti1CCNBkxkFCjP+G+77jPE/kFIlMuAizaFkWSaCUxrZtksj7gESNOM0wDGQ8YxxH2l6wGE5TFiEX8mjclU/mPGHnBrnzV6SUESmJodFFQ5h1bGqtobeEP9yLK9ZQfbojAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table8\"\n        title=\"table8\"\n        src=\"/static/9806589dda2f757e4fb7c696bb7a4acd/fcda8/table8.png\"\n        srcset=\"/static/9806589dda2f757e4fb7c696bb7a4acd/12f09/table8.png 148w,\n/static/9806589dda2f757e4fb7c696bb7a4acd/e4a3f/table8.png 295w,\n/static/9806589dda2f757e4fb7c696bb7a4acd/fcda8/table8.png 590w,\n/static/9806589dda2f757e4fb7c696bb7a4acd/9be90/table8.png 636w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>hidden size를 늘리면 증가의 폭이 줄지만 성능이 향상됨.</li>\n<li>hidden size 6144에서는 성능이 크게 저하됨.</li>\n</ul>\n<h2 id=\"48-what-if-we-train-for-the-same-amount-of-time\" style=\"position:relative;\"><a href=\"#48-what-if-we-train-for-the-same-amount-of-time\" aria-label=\"48 what if we train for the same amount of time permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.8 What if we train for the same amount of time?</h2>\n<ul>\n<li>표 3의 속도 향상 결과를 보면 BERT-large의 데이터 처리량이 ALBERT-xxlarge에 비해 약 3.17배 더 높음을 보여줌.</li>\n<li>일반적으로 training time이 길수록 성능이 향상되므로 training step을 제어하는 대신 실제 training time을 제어하는 비교를 수행.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 14.18918918918919%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAsklEQVQI1x2O246DMAwF+f9v214QEtqyQAmBhAQIgRda1Go24cGydDz2OGmF4Ha7s3jPcRyUZYmUkibkVfnHz+WKtZbH45csy9BKURQFXdcjAiOahrquqaqa1/tN4ubpBOOBdV3P5Xl2TNPEMAykacq2bTTPJ3mes+874zji/RLmBucc1hhE2/L5fElUMC6LR2t9grFU32MCNFqDCrkxli58HQVRFKVStpjQI6eUDtWf+T9xmN1hXUYg+AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table9\"\n        title=\"table9\"\n        src=\"/static/874ea5e470c7aa48d0a753a1a6d959ff/fcda8/table9.png\"\n        srcset=\"/static/874ea5e470c7aa48d0a753a1a6d959ff/12f09/table9.png 148w,\n/static/874ea5e470c7aa48d0a753a1a6d959ff/e4a3f/table9.png 295w,\n/static/874ea5e470c7aa48d0a753a1a6d959ff/fcda8/table9.png 590w,\n/static/874ea5e470c7aa48d0a753a1a6d959ff/13a9a/table9.png 637w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>BERT-large model(400k step)과 ALBERT-xxlarge model(125k step)의 training time은 거의 같다.(34h, 32h)</li>\n<li>ALBERT-xxlarge는 BERT-large와 거의 같은 시간을 training한 후 성능을 훨씬 더 좋음.</li>\n<li>average 1.5% 향상, RACE에서는 5.2% 향상</li>\n</ul>\n<h2 id=\"49-do-very-wide-albert-models-need-to-be-deeper-too\" style=\"position:relative;\"><a href=\"#49-do-very-wide-albert-models-need-to-be-deeper-too\" aria-label=\"49 do very wide albert models need to be deeper too permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.9 Do very wide ALBERT models need to be deep(er) too?</h2>\n<ul>\n<li>section 4.7에서 ALBERT-large의 경우 12-layer와 24-layer의 차이는 작다는 것을 확인할 수 있었음.</li>\n<li>이 결과가 ALBERT-xxlarge에도 적용되는지 확인.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 542px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 17.567567567567565%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAECAYAAACOXx+WAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA4ElEQVQY0x1Q2W6DMBDk/7+rkdKXRmqBlhI7iTGXDdhVCKfQdNcP1h5zaMeREFcIIaF1AXm7wxqDLMvw853C+T8opZDEMW6E9X2HJEkwDANpBIy1hD8gpERd1yirCtE8zzBkwgP3lkjx1yfeTicSuiB4P5+R51eM44jL5QPj64U0TdD1A9TjHgylFHTIL6LjODBNEyYy435dV4zPJ5zz2Pcdy7LAex84jDvngjHXbdsCzo93zInKskJn+cIaqlBoW4O2aUJUvlprjYbmkqoudEiT5zkq4jNWEK+huPxtnOYf1B0o4Csf1xcAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table10\"\n        title=\"table10\"\n        src=\"/static/f49e66f2b6e11c89e3abea78d49b44e0/c0388/table10.png\"\n        srcset=\"/static/f49e66f2b6e11c89e3abea78d49b44e0/12f09/table10.png 148w,\n/static/f49e66f2b6e11c89e3abea78d49b44e0/e4a3f/table10.png 295w,\n/static/f49e66f2b6e11c89e3abea78d49b44e0/c0388/table10.png 542w\"\n        sizes=\"(max-width: 542px) 100vw, 542px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>downstream task accuracy 측면에서 12-layer와 24-layer ALBERT-xxlarge 차이는 무시할 수 있으며 average 점수는 동일함.</li>\n<li>all cross-layer parameter를 sharing할 때 12-layer 구성보다 더 깊은 model이 필요하지 않다고 결론짓는다.</li>\n</ul>\n<h2 id=\"410-additional-training-data-and-dropout-effects\" style=\"position:relative;\"><a href=\"#410-additional-training-data-and-dropout-effects\" aria-label=\"410 additional training data and dropout effects permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.10 Additional training data and dropout effects</h2>\n<ul>\n<li>이 section에서는 XLNet, RoBERTa와 같이 additional data의 영향에 대한 결과를 보여줌.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 586px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.24324324324324%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABeElEQVQoz1VSia7bMAzL///jgLe0OZrTia/EjsNR6lpsAgQ5jkzSlCtrLWKMOI7jm1Hqeeo654xPSJ8PESEEze8Z6WVe14WqbVuklFBK0Y1CgHISiIfjbhG8V7DEA/M8w+4Or9cLPz+/Edgj5xJ7wrIikqRqmgblvt8SCBxdgDGeAAlXTqpKwpgVwzjhvouCaJI4GYOLQFlUsreq61qbgiXQFmAjFQL/XVMieIdxmrl6k5erwJtdgSXkdnL96jUM2N1Bb06cuRDgUDXzvGDbNv2WcM5iXhYYe6CdPDpmO/ov8V3uN+Dj8cROX3QYlL4SSHwV5dM0qflvBRkzv3/VA7phhbUO3jkSsdJDIZda5SwDufRqhn50Xadm3/RV8t8pyzqnk0AWK9U2TYuF9fNK5H+lftAHYROw5/NJtl3BdOoyfX0BWfdOmt91PQZaJXb1nLjsfUIB5RlM00iFm67HccTA+njUStL3/TfFjpFACsge2ZP+++9L+QPXarfL1nyOugAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig3\"\n        title=\"fig3\"\n        src=\"/static/88750f5dd4c750b31ece70557ccb2ebc/a76f4/fig3.png\"\n        srcset=\"/static/88750f5dd4c750b31ece70557ccb2ebc/12f09/fig3.png 148w,\n/static/88750f5dd4c750b31ece70557ccb2ebc/e4a3f/fig3.png 295w,\n/static/88750f5dd4c750b31ece70557ccb2ebc/a76f4/fig3.png 586w\"\n        sizes=\"(max-width: 586px) 100vw, 586px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 553px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 16.89189189189189%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAApklEQVQI1x2O2QqEMAxF5/8/TdvHauugL27dXRAUHbzTJnCTkJuE83nfF+u6Yp5nTNMEozV0UlkUYIzDew9WMnDOYYxBVVXkK6XgnIUQAl3XkXJ8chrHkYxa1mlRQhuLb6Mg0vF932jbFqpp8HseenRdF5SUOM+TvL7vaU4PvXMIIeA4DqqZNsaQaCy2bUsU2Y9pvlAflwX5ZhgG2ES87zuRW+uo/wN75t3k7OvfbwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table11\"\n        title=\"table11\"\n        src=\"/static/33f3a3feeb3291f6ec0e483f0cf2d65f/74cfa/table11.png\"\n        srcset=\"/static/33f3a3feeb3291f6ec0e483f0cf2d65f/12f09/table11.png 148w,\n/static/33f3a3feeb3291f6ec0e483f0cf2d65f/e4a3f/table11.png 295w,\n/static/33f3a3feeb3291f6ec0e483f0cf2d65f/74cfa/table11.png 553w\"\n        sizes=\"(max-width: 553px) 100vw, 553px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>그림 3a는 additional data가 있거나 없는 두 가지 조건에서 MLM accuracy를 나타내며, additional data가 있는 조간이 크게 향상되었음.</li>\n<li>또한 SQuAD benchmark(wikipedia 기반이므로 외부 domain data로부터 부정적인 영향)를 제외하고 표11의 downstream task에서도 성능 향상을 확인할 수 있음.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 581px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 16.216216216216214%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAAAsTAAALEwEAmpwYAAAApklEQVQI1z1PywqDMBD0/3/MHirYQwWDsVTNs2ojeDI1090UGlj2MbOzkwL0Yozw3kFpDWsdxnFEVV3R9w8opXApSzyHAV3XYaAspYQxBkII4vR5Hj8nS6FILHgcJMILEm0rsCwLmuaexbYt4FbXCGGDcw7r+oamw/u+UzZkxGOaJpxnQkoJBYPzPOf4LayZxDW7cFTzzFr7x9kli3D/Ipx5/KsQAr5ydt7ua9QqrwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table12\"\n        title=\"table12\"\n        src=\"/static/82c7c9865175037e878922c78d8c04e1/92d15/table12.png\"\n        srcset=\"/static/82c7c9865175037e878922c78d8c04e1/12f09/table12.png 148w,\n/static/82c7c9865175037e878922c78d8c04e1/e4a3f/table12.png 295w,\n/static/82c7c9865175037e878922c78d8c04e1/92d15/table12.png 581w\"\n        sizes=\"(max-width: 581px) 100vw, 581px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>또한 1M step을 training한 후에도 가장 큰 model은 train data에 대해 overfit되지 않는다.</li>\n<li>결과적으로 model capacity를 늘리기 위해 dropout을 제거하기로 하였음.</li>\n<li>그림 3b는 dropout을 제거하면 MLM의 정확도가 크게 향상됨을 보여줌.</li>\n<li>또한 ALBERT-xxlarge에 대한 중간 평가(표 12)는 dropout 제거가 downstream task에 도움이 되는 것을 확인할 수 있음.</li>\n<li>CNN(Convolutional Neural Network)에서 batch normalization과 dropout의 조합이 model의 성능을 저하시키는 경험적인 결과(Szegedy et al., 2017)와 이론적 증거(Li et al., 2019)가 있다.</li>\n<li>이를 통해 large transformer based model에서 dropout이 성능을 저하시킬 수 있음을 가장 먼저 보여준다.</li>\n</ul>\n<h2 id=\"411-current-state-of-the-aft-on-nlu-tasks\" style=\"position:relative;\"><a href=\"#411-current-state-of-the-aft-on-nlu-tasks\" aria-label=\"411 current state of the aft on nlu tasks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.11 Current State-of-the-aft on NLU Tasks</h2>\n<ul>\n<li>이 결과에서는 Devlin et al. 이 사용한 training data를 사용한다.</li>\n<li>single-model ALBERT configuration에는 MLM 및 SOP loss를 결합하고 dropout을 사용하지 않는 ALBERT-xxlarge configuration과 같은 SotA가 통합되어 있다.</li>\n<li>최종 ensemble model에 기여하는 checkpoint는 devset에 따라 결정함.</li>\n<li>single-model 및 ensemble-model의 결과는 ALBERT가 모두 SotA를 달성하였으며 GLUE score 89.4, SQuAD 2.0 F1 92.2 및 RACE test accuracy 89.4를 달성함을 확인할 수 있다.</li>\n<li>RACE의 경우 BERT에 비해 +17.4% XLNet에 비해 +7.6% RoBERTa에 비해 +6.2% DCMI에 비해 +5.3% 향상시켰다.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 47.2972972972973%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABlElEQVQozzVSi26CQBDk/z/Mxia1MWhRoSDv1/EQH2CsTndWvWTD3S43NzO7VmNq2LaNqq5hJDzPQxAEiKIIdV2hKApUVSV7qZsGSZKgbVvNGWM0yrJE0zQYhgEWN9+LLzjOBtP1iigMFZwAXdei7ToFaOTi4XDQ/PF0UkDmT7LnejweEoDV9z3m87mALgSgR55n6OUimeV5jv1+r6ziOEaeZaqgrg1CeZhnPkiwv9sN9/sdVisMP2Yz2KsVXNdV+Tv5rtdr7HY7rCS/3W41nwkAwck2TVM9U/I4jjifz5imCdZw6LFcLnG5jEo9pUfyKn/mJTKpxCPuu5d8ekXgQZRQfiZKaAHVqoefIpkAXEkSq2RKpGxlIkEAms8cgVnnmZ7GcaJNJJZFupQViFdcT9OPCtQIGyNTQC95mezeTWmk40Yb12kteSmzeCjLQiPPn414N4ShvgkbNqfgv1Ijm0JqBImiGKHUSICyLVIPAl+b4Ps+fJlBdtLzXLjSlF8/wMZx8CPxnk+SoK+cyyx7PsqZJft/swmbrzp6UD4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table13\"\n        title=\"table13\"\n        src=\"/static/0aac58a2fe64a9aa9984001b8f988763/fcda8/table13.png\"\n        srcset=\"/static/0aac58a2fe64a9aa9984001b8f988763/12f09/table13.png 148w,\n/static/0aac58a2fe64a9aa9984001b8f988763/e4a3f/table13.png 295w,\n/static/0aac58a2fe64a9aa9984001b8f988763/fcda8/table13.png 590w,\n/static/0aac58a2fe64a9aa9984001b8f988763/374ac/table13.png 634w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 46.621621621621614%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABh0lEQVQoz11S2XLCMAzM//8VbWkfKRByMCTkIpCLa4CEQNhqVShMNaOxLcu70srGfD7HdDpFWZbI8xyFrEkSw3YcBEGAUNx1XaRpqvdJkmCxWOieK535vuBUVQVj7vsYDocKWNcnHI9Hddd1MDYnuFwu8DwPvnjXdVhXpT6+Xq9y18KX9yyIBDTDm800QLvdbppIq+Rhulw+91IhLQwDDAbfaNsLrkK2Wq30brvd/gJGkmBZFjxhyrIcm81Ggfe7nQCtNYkxdkArywKUSVKEnICZgh4Oh2eFvd4bRqMRoihGURQCnOHrs4/3j762Ytu26ng6nVDImYBN02AnVZkiCyULw0i7M2YCODFNJHehydacz1LVWkXmw667/UnCOAdxblv8N2psBMIWx7G2tRYAtsaHr8bzI7YSXS3L1mExVte1Os/acipsjnyRVhhfh5LnGRb3QbBSktJ2ou1j3wiQ47gwx2NE95jBMulte9bq9vu9Tkz/pOj5GMhymeqZzpZJwj1XTvxR4Q+Lz6aVFH6BLAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table14\"\n        title=\"table14\"\n        src=\"/static/6fc73cbcc76da5fdb62a78c4f01b9ec6/fcda8/table14.png\"\n        srcset=\"/static/6fc73cbcc76da5fdb62a78c4f01b9ec6/12f09/table14.png 148w,\n/static/6fc73cbcc76da5fdb62a78c4f01b9ec6/e4a3f/table14.png 295w,\n/static/6fc73cbcc76da5fdb62a78c4f01b9ec6/fcda8/table14.png 590w,\n/static/6fc73cbcc76da5fdb62a78c4f01b9ec6/738b8/table14.png 639w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h1 id=\"5-discussion\" style=\"position:relative;\"><a href=\"#5-discussion\" aria-label=\"5 discussion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Discussion</h1>\n<ul>\n<li>ALBERT-xxlarge는 BERT-large보다 parameter가 적고 훨씬 더 좋은 성능을 보여줌. 그러나 large structure로 인해 계산비용이 더 비싸다.</li>\n<li>따라서 중요한 다음 단계는 sparse attention<a href=\"https://arxiv.org/abs/1904.10509\">(link)</a> 및 block attention<a href=\"https://arxiv.org/abs/1804.00857\">(link)</a>과 같은 방법을 통해 ALBERT의 train 및 inference속도를 높이는 것이다.</li>\n<li>추가적인 representation power를 연구는 hard example mining<a href=\"https://arxiv.org/abs/1310.4546\">(link)</a>과 보다 효율적인 modeling training(XLNet)이 포함된다.</li>\n<li>또한 SOP가 더 나은 language representation으로 이어지는 설득력 있는 증거를 가지고 있지만, 우리는 self-supervised training에서 결과적인 representation에 대한 추가적인 representation을 생성할 수있는 더 많은 차원이 있을 수 있다고 가정한다.</li>\n</ul>\n<h1 id=\"a-appendix\" style=\"position:relative;\"><a href=\"#a-appendix\" aria-label=\"a appendix permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A. Appendix</h1>\n<h2 id=\"a2-hyperparamters\" style=\"position:relative;\"><a href=\"#a2-hyperparamters\" aria-label=\"a2 hyperparamters permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A.2 Hyperparamters</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABd0lEQVQoz1VS25aCMBDz/7/Lt1VfXVwRECj3u+BRhOxkRHedc0rLdJpJ0q4gMU0TbrcbxnHE0PcoyxK9zHmeo64rnM9nzVVVhSgyuu66TmuYY93lciEUVrN85nnGybZhohhhEGC9XiOOI4ShQS+FxoR6oG1buK6L6/UKy/qWRr428zwPWZYtgPOsC+dkI0lSlEWB3W6HUjpzMIZh0Fk6o5B9hm0f4fsBAiGQS65tu09AMkzSP8CiKPUw9ymR8+PxUHkMz3NVAdkxR/YfgAeREC8MvzYb9aaq63+A4rUAZgsgpRLIGKONm6Z5AqokMXe/38MX+vRws90qYLEwawR4Uobj2ysyTEURbWKulpo34P1+V7PLstKNn+NRb5Djw0MJ3i4jTRNpWqvPlMuLUkDSJhtSD3xffAnlaURIkwSO4+g/mbzycRyLxFz/fannpTDHC0rkzOpwsOQJWJokIL2hJxyUb0ykklhMkEBGplJjaSDPLHwCvYB/ARhAqErZ4pgHAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table15\"\n        title=\"table15\"\n        src=\"/static/5651b649e1d0e36fccff49744333bf9d/fcda8/table15.png\"\n        srcset=\"/static/5651b649e1d0e36fccff49744333bf9d/12f09/table15.png 148w,\n/static/5651b649e1d0e36fccff49744333bf9d/e4a3f/table15.png 295w,\n/static/5651b649e1d0e36fccff49744333bf9d/fcda8/table15.png 590w,\n/static/5651b649e1d0e36fccff49744333bf9d/9be90/table15.png 636w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>","frontmatter":{"title":"[논문리뷰] ALBERT: A Lite BERT for Self-supervised Learning of Language Representations","date":"September 02, 2019"}}},"pageContext":{"slug":"/NLP/albert/","previous":{"fields":{"slug":"/Multi_Modal/epic/"},"frontmatter":{"title":"[논문리뷰] EPIC-Fusion: Audio-Visual Temporal Binding for Egocentric Action Recognition","category":"Multi_Modal","draft":false}},"next":{"fields":{"slug":"/NLP/finbert/"},"frontmatter":{"title":"[논문리뷰] FinBERT: Financial Sentiment Analysis with Pre-trained Language Models","category":"NLP","draft":false}}}},"staticQueryHashes":["3128451518","96099027"]}