{"componentChunkName":"component---src-templates-blog-post-js","path":"/NLP/mixreview/","result":{"data":{"site":{"siteMetadata":{"title":"Deep Learner","author":"[Jeonsworld]","siteUrl":"https:jeonsworld.github.io","comment":{"disqusShortName":"","utterances":"jeonsworld/blog-comment"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"1812b1c9-02b2-5e51-9f19-571365daf45d","excerpt":"Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for Neural Language Generation Models Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut https://arxiv.org/abs/1910.07117 1. Introduction large-scale unsupervised pre…","html":"<blockquote>\n<p><strong>Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for Neural Language Generation Models</strong><br>\nZhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut<br>\n<a href=\"https://arxiv.org/abs/1910.07117\">https://arxiv.org/abs/1910.07117</a></p>\n</blockquote>\n<h1 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Introduction</h1>\n<p>large-scale unsupervised pre-training의 큰 성공과 함께 NLP model의 성능과 많은 연구 관심을 끌었다.\n큰 성공에도 불구하고 다음과 같은 open question을 던질 수 있다.\n“standard NLP pretrain-finetune framework에 weakness가 있습니까?”\n본 논문에서는 language generation에 관점을 두며 위의 질문에 대답이 yes 라는 것을 보여준다.\n특히, 이 질문에 답이 <strong>data separation</strong>으로 나타나는 개념이라는 것을 알게 되었음.</p>\n<p>pretrain-finetune framework는 크게 두 가지 과정으로 볼 수 있다.</p>\n<ol>\n<li>large-scale text data를 통해 model을 pre-train</li>\n<li>target task data를 통해 model을 fine-tune</li>\n</ol>\n<p>data separation은 두 단계에서(거의) 겹치지 않는 data usage를 나타낸다.</p>\n<p>본 논문에서는 NLG(natural language generation)의 관점에서 pretrain-finetune framework를 연구하며 다음의 이유로 open-domain dialogue response task에 중점을 둔다.</p>\n<ol>\n<li>target dialogue response task(conditional NLG)와 pre-training language modeling objective간에 similarity가 높으므로 pre-training과정에서 습득한 language generation 기술이 downstream target task로 잘 transfer될 수 있을것으로 기대.</li>\n<li>model의 sequence-to-sequence 특성을 통해 model의 generation 동작을 다양한 방식(e.g., context sensitivity)으로 특성화 할 수 있음.</li>\n</ol>\n<h3 id=\"contribution\" style=\"position:relative;\"><a href=\"#contribution\" aria-label=\"contribution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Contribution</h3>\n<ul>\n<li>pretrain-finetune이 model의 행동을 어떻게 변화시키는지 연구하기 위해 <strong>context sensitivity와 knowledge transfer관점</strong>에서 행동 분석을 수행.</li>\n<li>main finding은 fine-tuning 단계에서 data separation으로 인해 model이 pre-train과정에서 습득한 중요한 language generation skill을 잊게 한다는 것.</li>\n<li>이러한 분석을 통해 data mixing concept를 채택하고 pre-training, fine-tuning을 결합한 <strong>mix-review fine-tuning strategy를 제안</strong>.</li>\n<li>mix-review가 fine-tuning process를 효과적으로 <strong>regularization하고 forgetting problem을 크게 완화</strong>함.</li>\n</ul>\n<h1 id=\"2-training-objective-for-seq2seq-tasks\" style=\"position:relative;\"><a href=\"#2-training-objective-for-seq2seq-tasks\" aria-label=\"2 training objective for seq2seq tasks permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. Training Objective for Seq2seq Tasks</h1>\n<p>End-to-End dialogue response generation은 seq2seq task로 공식화 할 수 있다.\ndialogue context(previous utterances)가 주어지면 model은 response를 생성하도록 요청한다.\n이러한 task에서는 encoder-decoder model architecture를 주로 사용.  </p>\n<p>본 논문에서는 Vaswani et al.(2017)과 같이 6개의 transformer encoder/decoder를 사용한다.</p>\n<ul>\n<li>attention head:16, embedding dim:1024, ffn dim:4096</li>\n</ul>\n<p>Adam optimizer를 사용하며 data distribution의 input sequence <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">x</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{x}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.44444em;vertical-align:0em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">x</span></span></span></span></span>를 고려하여 target sentence <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi mathvariant=\"bold\">y</mi></mrow><annotation encoding=\"application/x-tex\">\\mathbf{y}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.63888em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">y</span></span></span></span></span>의 negative log-likelihood를 최소화함.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">L</mi><mrow><mi>M</mi><mi>L</mi><mi>E</mi></mrow></msub><mrow><mo fence=\"true\">(</mo><msub><mi>P</mi><mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub><mo separator=\"true\">;</mo><mi>θ</mi><mo fence=\"true\">)</mo></mrow><mo>=</mo><msub><mi>E</mi><mrow><mrow><mo fence=\"true\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo fence=\"true\">)</mo></mrow><mo>∼</mo><msub><mi>P</mi><mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></mrow></msub><mrow><mo fence=\"true\">(</mo><mrow><mo>−</mo><mi mathvariant=\"normal\">l</mi><mi mathvariant=\"normal\">o</mi><mi mathvariant=\"normal\">g</mi></mrow><msub><mi>P</mi><mi>θ</mi></msub><mrow><mo fence=\"true\">(</mo><mi mathvariant=\"bold\">y</mi><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"bold\">x</mi><mo fence=\"true\">)</mo></mrow><mo fence=\"true\">)</mo></mrow><mo>=</mo><msub><mi>E</mi><mrow><mrow><mo fence=\"true\">(</mo><mi>x</mi><mo separator=\"true\">,</mo><mi>y</mi><mo fence=\"true\">)</mo></mrow><mo>∼</mo><msub><mi>P</mi><mrow><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub></mrow></msub><mrow><mo fence=\"true\">(</mo><mo>−</mo><munderover><mo>∑</mo><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><mrow><mrow><mi mathvariant=\"normal\">l</mi><mi mathvariant=\"normal\">o</mi><mi mathvariant=\"normal\">g</mi></mrow><msub><mi>P</mi><mi>θ</mi></msub><mrow><mo fence=\"true\">(</mo><msub><mi>y</mi><mi>t</mi></msub><mi mathvariant=\"normal\">∣</mi><msub><mi mathvariant=\"bold\">y</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub><mo separator=\"true\">,</mo><mi mathvariant=\"bold\">x</mi><mo fence=\"true\">)</mo></mrow></mrow><mo fence=\"true\">)</mo></mrow><mo separator=\"true\">,</mo><mspace width=\"1em\"/><mo stretchy=\"false\">(</mo><mn>1</mn><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">\\mathcal{{ L  }}_{ MLE }\\left( { P }_{ data };\\theta  \\right) ={ E }_{ \\left( x,y \\right) \\sim { P }_{ data } }\\left( \\mathrm{-log}{ P }_{ \\theta  }\\left( \\mathbf{y}|\\mathbf{x} \\right)  \\right) ={ E }_{ \\left( x,y \\right) \\sim { P }_{ data } }\\left( -\\sum _{ t=1 }^{ m }{ \\mathrm{log}{ P }_{ \\theta  }\\left( { y }_{ t }|\\mathbf{{ y }}_{ &lt;t },\\mathbf{x} \\right)  }  \\right) ,\\quad (1)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.32833099999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10903em;\">M</span><span class=\"mord mathdefault mtight\">L</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.05764em;\">E</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.1052em;vertical-align:-0.3551999999999999em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mathdefault mtight\">x</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\">−</span><span class=\"mord mathrm\">l</span><span class=\"mord mathrm\">o</span><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">y</span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:3.017113em;vertical-align:-1.267113em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.34480000000000005em;\"><span style=\"top:-2.5198em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"minner mtight\"><span class=\"mopen mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">(</span></span><span class=\"mord mathdefault mtight\">x</span><span class=\"mpunct mtight\">,</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">y</span><span class=\"mclose mtight delimcenter\" style=\"top:0em;\"><span class=\"mtight\">)</span></span></span><span class=\"mrel mtight\">∼</span><span class=\"mord mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3448em;\"><span style=\"top:-2.3487714285714287em;margin-right:0.07142857142857144em;\"><span class=\"pstrut\" style=\"height:2.5em;\"></span><span class=\"sizing reset-size3 size1 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">d</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15122857142857138em;\"><span></span></span></span></span></span></span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3551999999999999em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">(</span></span><span class=\"mord\">−</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mop op-limits\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.6513970000000002em;\"><span style=\"top:-1.882887em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mrel mtight\">=</span><span class=\"mord mtight\">1</span></span></span></span><span style=\"top:-3.050005em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span><span class=\"mop op-symbol large-op\">∑</span></span></span><span style=\"top:-4.3000050000000005em;margin-left:0em;\"><span class=\"pstrut\" style=\"height:3.05em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:1.267113em;\"><span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathrm\">l</span><span class=\"mord mathrm\">o</span><span class=\"mord mathrm\" style=\"margin-right:0.01389em;\">g</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.33610799999999996em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">θ</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mord\">∣</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">y</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">&lt;</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord mathbf\">x</span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size4\">)</span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mspace\" style=\"margin-right:1em;\"></span><span class=\"mopen\">(</span><span class=\"mord\">1</span><span class=\"mclose\">)</span></span></span></span></span>\n<p><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"bold\">y</mi><mrow><mo>&lt;</mo><mi>t</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">\\mathbf{{ y }}_{ &lt;t }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.63888em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathbf\" style=\"margin-right:0.01597em;\">y</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.2805559999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mrel mtight\">&lt;</span><span class=\"mord mathdefault mtight\">t</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.17737em;\"><span></span></span></span></span></span></span></span></span></span>는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">{</mo><msub><mi>y</mi><mn>0</mn></msub><mo separator=\"true\">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo separator=\"true\">,</mo><mo>…</mo><mo separator=\"true\">,</mo><msub><mi>y</mi><mrow><mi>t</mi><mo>−</mo><mn>1</mn></mrow></msub><mo fence=\"true\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\left\\{ { y }_{ 0 },{ y }_{ 1 },\\dots ,{ y }_{ t-1 } \\right\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\">…</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.301108em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.208331em;\"><span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span></span></span></span> 를 나타내며 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mn>0</mn></msub></mrow><annotation encoding=\"application/x-tex\">{ y }_{ 0 }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.30110799999999993em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">0</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>는 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>&lt;</mo><mi>B</mi><mi>O</mi><mi>S</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">&lt;BOS&gt;</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05017em;\">B</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span> token이고 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>y</mi><mi>m</mi></msub></mrow><annotation encoding=\"application/x-tex\">{y}_{m}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.625em;vertical-align:-0.19444em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.03588em;\">y</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.151392em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">m</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15em;\"><span></span></span></span></span></span></span></span></span></span>은 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo>&lt;</mo><mi>E</mi><mi>O</mi><mi>S</mi><mo>&gt;</mo></mrow><annotation encoding=\"application/x-tex\">&lt;EOS&gt;</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.5782em;vertical-align:-0.0391em;\"></span><span class=\"mrel\">&lt;</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.72243em;vertical-align:-0.0391em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">E</span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">O</span><span class=\"mord mathdefault\" style=\"margin-right:0.05764em;\">S</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">&gt;</span></span></span></span> token 이다.\ndialogue response setting에서 input <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>는 이전 발화의 연결이며 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>x</mi></mrow><annotation encoding=\"application/x-tex\">x</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.43056em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">x</span></span></span></span>의 길이를 최대 128 word로 잘라낸다. 일반적으로 6개의 이전 발화가 포함됨.  </p>\n<p>trained seq2seq model로 부터 contexual input에 맞는 response를 generation하기 위해 decoding method를 선택해야 함.\n최근연구(Holtzman et al., 2019; Radford et al., 2019; Fan et al., 2018)에 따르면 top-k sampling이라는 strategy가 있으며 다음 단어는 k개의 가장 가능성이 높은 선택에서 샘플링된다.</p>\n<ul>\n<li>Holtzman et al.: The curious case of neural text degeneration.</li>\n<li>Radford et al.: Language models are unsupervised multitask learners.</li>\n<li>Fan et al.: Hierarchical neural story generation.  </li>\n</ul>\n<p>이는 기존의 beam search decoding보다 더 나은 선택이다.\npreliminary experiments(Appendix A)에서 결과를 확인할 수 있음.  </p>\n<p>본 연구에서는 따로 언급하지 않는 한 top-k sampling을 기본 decoding method로 사용하며 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>k</mi></mrow><annotation encoding=\"application/x-tex\">k</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.03148em;\">k</span></span></span></span>는 30으로 설정.</p>\n<h1 id=\"3-the-pretrain-finetune-framework\" style=\"position:relative;\"><a href=\"#3-the-pretrain-finetune-framework\" aria-label=\"3 the pretrain finetune framework permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. The Pretrain-Finetune Framework</h1>\n<p>본 Section에서는 encoder-decoder model을 위한 pretrain-finetune framework를 review.\npre-training과정에서 model이 습득할 수 있는 language generation skill과 target task로 얼마나 잘 transfer되는지에 대해 논의한다.\n이 논의는 mix-review fine-tuning strategy 제안으로 이어짐.</p>\n<h2 id=\"31-pre-training\" style=\"position:relative;\"><a href=\"#31-pre-training\" aria-label=\"31 pre training permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1 Pre-training</h2>\n<p>large-scale unsupervised text data를 통해 seq2seq model을 pre-train하고 target dialogue data를 통해 fine-tune진행.\n대표적인 두 가지 pre-train strategy next sentence(NS) pre-train과 masked seq2seq (MASS) pre-train를 비교.</p>\n<ul>\n<li>next sentence는 GPT style LM training을 개선한 버전.</li>\n<li>MASS는 encoder-decoder model을 위한 “BERT”의 개선 버전.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 33.108108108108105%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABL0lEQVQoz1WS6Y6CQBCEef+nWuNGjSawRggJl1wbuQQEwz+t7WrQuCSdnu6ZfF01g5GmCZIkwTAMGG433D6i7/u5L8F127b/ous63ePZ+/2O5/MJ43DY42u1wna7hed5iKII53OMOI4RBAF+8xx1XWMcR1RVpZDr9apAgj4/BR6PP9hsNlivv2HbNizLVFCeZ4hFOcGJuOgWhcXlgrIsUQpcs8RFev0CNyzTFHU7Vei6LrIsg+/7qjQMQ80MBcsA9nzfQybK+75TxRxEyzPQsrDbzUAqTNNUAZz6uifa5ZqZddM0aOQaalHJc+w/Ho8ZSHuO4+B0OilM1YmKfLk7Wqs/7LFXLXVRFO+aQ6ZpgkELZ1Fk247YCTTTHi98fuHx/er6qq+/QPZY0+qwrKn0Dyt1BjkRU+iKAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table\"\n        title=\"table\"\n        src=\"/static/a0c5954f75da600b3cc758b2069d1cab/fcda8/table1.png\"\n        srcset=\"/static/a0c5954f75da600b3cc758b2069d1cab/12f09/table1.png 148w,\n/static/a0c5954f75da600b3cc758b2069d1cab/e4a3f/table1.png 295w,\n/static/a0c5954f75da600b3cc758b2069d1cab/fcda8/table1.png 590w,\n/static/a0c5954f75da600b3cc758b2069d1cab/efc66/table1.png 885w,\n/static/a0c5954f75da600b3cc758b2069d1cab/fd84e/table1.png 1056w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>표1 에서는 NS pre-train과 전형적인 dialogue response training의 유사성을 보여준다.\nNS pre-train에 비해 <strong>MASS는 한 번에 하나의 문장에 집중</strong>한다는 단점이 있음</p>\n<p>pre-train에서 model이 획들 수 있는 두가지 중요한 generation 기능이 있으며, 이는 dialogue setting에 이점이 있다.</p>\n<ul>\n<li>knowledge 습득: <strong>large-scale pre-train에는 많은 knowledge가 포함</strong>되어 있으며 dialogue response을 보다 유익하고 흥미롭게 만드는데 사용될 수 있음.(e.g., model에게 어벤져스 영화를 주제로 학습)</li>\n<li>contextual input의 활용: 현재의 open-domain dialogue model(without pre-training)은 contextual input에 둔감하여 generic response problem을 야기함. NS pre-train에 대한 preliminary experiment에서 GPT와 유사하게 pre-train model이 이전 sentence를 입력으로하여 밀접하게 관련된 response를 generation할 수 있음을 발견함. 이상적으로 fine-tune을 진행하는 동안 model은 이러한 skill을 <strong>target dialogue task로 transfer할 수 있음.</strong> </li>\n</ul>\n<h2 id=\"32-the-mix-review-fine-tuning-strategy\" style=\"position:relative;\"><a href=\"#32-the-mix-review-fine-tuning-strategy\" aria-label=\"32 the mix review fine tuning strategy permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.2 The Mix-review Fine-tuning Strategy</h2>\n<p>최근에는 다양한 NLP task에 대한 pre-train strategy가 제안되었지만 fine-tunuing 단계는 small lr로 parameter들을 fine-tune하기 때문에 간단함.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABsElEQVQoz31S27KiQAzk/z/QPQ9HUQQBFRiY+wV7k+hWnToPm6qGGdLTkzSpUs6w24bp+cT9fsc43mGtRSkZ3mfEyIi0L3BGQy0zcUbBRufevPThRlSZBNW84Ph9xNfXHxwOByyLQkrAPGt6JxFjntUa9ekkHEbf30hkpxwkmCeC2niprK4vuFzOIvh6AS8U8JM5DOci+mHE8Vijaa64Xq8wJomg96B8RuWcg1Ia21rkI1fGBMFnnRLnHPRGLc8Z1DkdBgLxQyCxQFcXyKUVe6A2g6FrMfUdln7Aehtgxgn6dieM8CRU9kLVOIy3DvbRIjxHRDWDKgEZC2oLhSyp3h69TVB6gXYrfHGwScNnh7xHxBSoyix+cphosIVNoLzC6le45OCj5woL/VXa+CAIgRGpDQ9jDVazwjqLfd/B9nA+Uj5/LnCBrLBkhVaCCr9CU9mPx0NG4H/hyfC+7+Xyn1Hx4XVd8aQ55HVLf+58PsucTdMk74X8+cdTStE4zRiGAW3biijnt+2dq5rmQgIXGhkehQZd19HoNCLMY3E61SQ6S+VcFbfNg89r7uLnntd/AWSYANjk5oqmAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig1\"\n        title=\"fig1\"\n        src=\"/static/75fd2e27d41dc9f7a3879949a25a67b1/fcda8/fig1.png\"\n        srcset=\"/static/75fd2e27d41dc9f7a3879949a25a67b1/12f09/fig1.png 148w,\n/static/75fd2e27d41dc9f7a3879949a25a67b1/e4a3f/fig1.png 295w,\n/static/75fd2e27d41dc9f7a3879949a25a67b1/fcda8/fig1.png 590w,\n/static/75fd2e27d41dc9f7a3879949a25a67b1/efc66/fig1.png 885w,\n/static/75fd2e27d41dc9f7a3879949a25a67b1/1be7e/fig1.png 1059w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>그림 1a에서 fine-tuning동안 다양한 eval set에 대한 model의 NLL를 확인할 수 있음.  </p>\n<p>fine-tuning중 두 가지 잠재적 문제를 식별할 수 있음.</p>\n<ol>\n<li>over-fitting: trainset NLL과 validation-set NLL사이의 간격이 빠르게 증가함.</li>\n<li>\n<p>forgetting: pre-train CC-NEWS data의 성능이 크게 떨어짐. 여기서 forgetting 현상은 sequential learning case에서와 같이 “재앙적(catastrophic)“이지는 않다. </p>\n<ul>\n<li>그러나 model이 pre-training 과정에서 배운 중요한 skill을 잃어버렸다고 의심하게 만듦.(senction 5.2, 5.3)</li>\n</ul>\n</li>\n</ol>\n<p>forgetting 현상을 해결하기 위해 “Mix-Review”라는 fine-tuning strategy를 제안.\n각 fine-tuning 단계마다 target dialogue data를 pre-train data의 random한 subset과 mix한다.\n이에 해당하는 두 가지 hyper-param을 소개.</p>\n<ul>\n<li>mix-ratio는 pre-train data에서 얼마나 mix할껀지 제어하고, mix-decay는 mix data의 양을 각 epoch마다 감소시킨다.</li>\n<li>예를들어, target dialogue trainingset에 100k의 발화(문맥), mix-ratio=4, mix-decay=0.9면 mix-review fine-tuning의 첫번째 epoch에는 400k pre-train 발화가 포함되며 두번째 epoch에는 360k 발화로 감소.</li>\n<li>mix-review objective는 다음과 같이 공식화 됨.</li>\n</ul>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">L</mi><mrow><mi>f</mi><mi>i</mi><mi>n</mi><mi>e</mi><mo>−</mo><mi>t</mi><mi>u</mi><mi>n</mi><mi>e</mi></mrow></msub><mrow><mo fence=\"true\">(</mo><msub><mi>P</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mo>−</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub><mo separator=\"true\">;</mo><mi>θ</mi><mo fence=\"true\">)</mo></mrow><mo>+</mo><mrow><mi mathvariant=\"normal\">m</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">x</mi><mo>−</mo></mrow><mrow><mi mathvariant=\"normal\">r</mi><mi mathvariant=\"normal\">a</mi><mi mathvariant=\"normal\">t</mi><mi mathvariant=\"normal\">i</mi><mi mathvariant=\"normal\">o</mi></mrow><mo>⋅</mo><msub><mi mathvariant=\"script\">L</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mo>−</mo><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi></mrow></msub><mrow><mo fence=\"true\">(</mo><msub><mi mathvariant=\"script\">L</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi><mi>t</mi><mi>r</mi><mi>a</mi><mi>i</mi><mi>n</mi><mo>−</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub><mo separator=\"true\">;</mo><mi>θ</mi><mo fence=\"true\">)</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\mathcal{{ L }}_{ fine-tune }\\left( { P }_{ target-data };\\theta  \\right) +\\mathrm{mix-}\\mathrm{ratio}\\cdot \\mathcal{{ L }}_{ pre-train }\\left(\\mathcal{L}_{ pretrain-data };\\theta  \\right)</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\">d</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.75119em;vertical-align:-0.08333em;\"></span><span class=\"mord\"><span class=\"mord mathrm\">m</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">x</span><span class=\"mord\">−</span></span><span class=\"mord\"><span class=\"mord mathrm\">r</span><span class=\"mord mathrm\">a</span><span class=\"mord mathrm\">t</span><span class=\"mord mathrm\">i</span><span class=\"mord mathrm\">o</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.311664em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\">d</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span></span></span></span></span>\n<p>mix-ratio와 mix-decay에 대해 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mrow><mo fence=\"true\">{</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>2</mn><mo separator=\"true\">,</mo><mn>4</mn><mo separator=\"true\">,</mo><mn>8</mn><mo separator=\"true\">,</mo><mn>16</mn><mo fence=\"true\">}</mo></mrow><mo>×</mo><mrow><mo fence=\"true\">{</mo><mn>1</mn><mo separator=\"true\">,</mo><mn>0.9</mn><mo separator=\"true\">,</mo><mn>0.8</mn><mo separator=\"true\">,</mo><mn>0.7</mn><mo separator=\"true\">,</mo><mn>0.6</mn><mo separator=\"true\">,</mo><mn>0.5</mn><mo fence=\"true\">}</mo></mrow></mrow><annotation encoding=\"application/x-tex\">\\left\\{ 1,2,4,8,16 \\right\\} \\times \\left\\{ 1,0.9,0.8,0.7,0.6,0.5 \\right\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">2</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">4</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">8</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">1</span><span class=\"mord\">6</span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">×</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">{</span><span class=\"mord\">1</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">9</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">8</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">7</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">6</span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\">0</span><span class=\"mord\">.</span><span class=\"mord\">5</span><span class=\"mclose delimcenter\" style=\"top:0em;\">}</span></span></span></span></span> 로 hyperparam tune을 진행했음.\nmix-review의 성능이 hyper-param에 민감하지 않다는 것을 발견. 일반적으로 4의 mix-ratio는 잘 작동함.</p>\n<p>그림 1a에서 mix-ratio가 4이고 mix-decay가 0.7인 mix-review fine-tuning에 대한 loss curve를 확인할 수 있음.\npre-train CC-NEWS data의 성능이 보존되어 mix-review가 의미있다는 것을 확인할 수 있음.\n또한 mix-review에서 regularization effect를 관찰.(training과 testing 성능 차이를 좁힘)  </p>\n<p>pre-trained parameter <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span> 에 대한 L2 regularization(weight decay)와 mix-review를 비교한다. 이를 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)로 표시하고 다음과 같이 공식화함.</p>\n<span class=\"katex-display\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi mathvariant=\"script\">L</mi><mrow><mi>f</mi><mi>i</mi><mi>n</mi><mi>e</mi><mo>−</mo><mi>f</mi><mi>u</mi><mi>n</mi><mi>e</mi></mrow></msub><mrow><mo fence=\"true\">(</mo><msub><mi>P</mi><mrow><mi>t</mi><mi>a</mi><mi>r</mi><mi>g</mi><mi>e</mi><mi>t</mi><mo>−</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow></msub><mo separator=\"true\">;</mo><mi>θ</mi><mo fence=\"true\">)</mo></mrow><mo>+</mo><mi>λ</mi><mo>⋅</mo><mo>∥</mo><mi>θ</mi><mo>−</mo><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub><msubsup><mo lspace=\"0em\" rspace=\"0em\">∥</mo><mn>2</mn><mn>2</mn></msubsup></mrow><annotation encoding=\"application/x-tex\">\\mathcal{{ L }}_{ fine-fune }\\left( { P }_{ target-data };\\theta  \\right) +\\lambda \\cdot \\parallel \\theta -{ \\theta  }_{ pre }{ \\parallel  }_{ 2 }^{ 2 }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.036108em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathcal\">L</span></span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault mtight\">i</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.10764em;\">f</span><span class=\"mord mathdefault mtight\">u</span><span class=\"mord mathdefault mtight\">n</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\">(</span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.13889em;\">P</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.3361079999999999em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.03588em;\">g</span><span class=\"mord mathdefault mtight\">e</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mbin mtight\">−</span><span class=\"mord mathdefault mtight\">d</span><span class=\"mord mathdefault mtight\">a</span><span class=\"mord mathdefault mtight\">t</span><span class=\"mord mathdefault mtight\">a</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mpunct\">;</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mclose delimcenter\" style=\"top:0em;\">)</span></span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">+</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1em;vertical-align:-0.25em;\"></span><span class=\"mord mathdefault\">λ</span><span class=\"mord\">⋅</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span><span class=\"mrel\">∥</span><span class=\"mspace\" style=\"margin-right:0.2777777777777778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.77777em;vertical-align:-0.08333em;\"></span><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span><span class=\"mbin\">−</span><span class=\"mspace\" style=\"margin-right:0.2222222222222222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.150216em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mrel\">∥</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8641079999999999em;\"><span style=\"top:-2.4530000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span><span style=\"top:-3.113em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">2</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.247em;\"><span></span></span></span></span></span></span></span></span></span></span>\n<p>실험에서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">λ</span></span></span></span>를 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo fence=\"true\">{</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>1</mn></mrow></msup><mo separator=\"true\">,</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>2</mn></mrow></msup><mo separator=\"true\">,</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>3</mn></mrow></msup><mo separator=\"true\">,</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>4</mn></mrow></msup><mo separator=\"true\">,</mo><msup><mn>10</mn><mrow><mo>−</mo><mn>5</mn></mrow></msup><mo fence=\"true\">}</mo></mrow><annotation encoding=\"application/x-tex\">\\left\\{ { 10 }^{ -1 },{ 10 }^{ -2 },{ 10 }^{ -3 },{ 10 }^{ -4 },{ 10 }^{ -5 } \\right\\}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:1.20001em;vertical-align:-0.35001em;\"></span><span class=\"minner\"><span class=\"mopen delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">{</span></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.848448em;\"><span style=\"top:-3.09734em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">1</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.848448em;\"><span style=\"top:-3.09734em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">2</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.848448em;\"><span style=\"top:-3.09734em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">3</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.848448em;\"><span style=\"top:-3.09734em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">4</span></span></span></span></span></span></span></span></span><span class=\"mpunct\">,</span><span class=\"mspace\" style=\"margin-right:0.16666666666666666em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord\">1</span><span class=\"mord\">0</span></span><span class=\"msupsub\"><span class=\"vlist-t\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.848448em;\"><span style=\"top:-3.09734em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mtight\">−</span><span class=\"mord mtight\">5</span></span></span></span></span></span></span></span></span><span class=\"mclose delimcenter\" style=\"top:0em;\"><span class=\"delimsizing size1\">}</span></span></span></span></span></span>로 조정하고 validation set에 기초한 최상의 모델로 첨부함.  </p>\n<p>그림 1b에서 <span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>λ</mi></mrow><annotation encoding=\"application/x-tex\">\\lambda</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.69444em;vertical-align:0em;\"></span><span class=\"mord mathdefault\">λ</span></span></span></span>가 0.1인 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)에 대한 loss curve를 보여줌. WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)에도 regularization 효과가 있지만 mix-review만큼 강력하진 않음.<br>\n또한 추가적으로 다음 두 가지 regularization techniques를 적용함</p>\n<ol>\n<li>dropout rate 증가</li>\n<li>\n<p>fine-tuning중에 하단 layer를 고정</p>\n<ul>\n<li>그러나 이 두가지 techniques를 통해 전혀 개선되지 않음. 그 이유는 transformer가 이미 well-tuned model이라고 생각(e.g., transformer에는 dropout, layer normalization이 포함되어 있음)</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"4-data-sets-and-implementation-details\" style=\"position:relative;\"><a href=\"#4-data-sets-and-implementation-details\" aria-label=\"4 data sets and implementation details permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Data-sets and Implementation Details</h1>\n<h2 id=\"41-data-sets\" style=\"position:relative;\"><a href=\"#41-data-sets\" aria-label=\"41 data sets permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.1 Data-sets</h2>\n<ul>\n<li>pre-training을 위해 CommonCrawl news dataset의 영어 부분에서 중복이 제거된 large-scale CC-NEWS data를 사용</li>\n<li>총 10억개 문장 또는 270억개의 단어로 구성</li>\n<li>합리적인 시간에 실험을 완료하기 위해 CCNEWS data의 처음 10%만 사용하여 pre-train 진행(1억개의 문장, 27억개의 단어)</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 36.486486486486484%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABZElEQVQoz01Ra2+CQBDk//+bNkqqRkQEBBRjrZGnoKA8Go0pPvg43b1G0w+X29uZnZ3dk/I8Q5KmaJoGbdvicrmgKAqEYYjVaoUgCFBVNXzPg2VZGKkqbNtCQPjxeBT4ZrNBHMfEqyCt12vM53Msl5/wqCjebhFFITRNw3CoiPuLOGEYYGqaGAwGsGwbvu/DcRziDKHrOgzDQJIkkGYzB73eByYTnZyVOJ1Ooqth6DCnU7iuS44cLBYucSaimIXYBDcbj8fEWcA0DXh+AEmMMRqJcdj24XCAS2S520Wn0xGdbXKkUaEsy8RVhSjn+v0+3t7foSgKVNLgaaU8z7GlMev6G9frVeyypB2y/f1+D8aLshSN0t1O7JfzJeX45v0zZ0fY+XyGxIUVgfwJHDMQx5Fwm2XZS5jzaZqI9zPHuMBINIoiMlX/CfKDf4wd8rnf76+Yz+12E4fd/8eb5kfEz/zj0eIX0lTvbG1lQBMAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table2\"\n        title=\"table2\"\n        src=\"/static/0a340e681f1383cb2fcc7f57f041ea1f/fcda8/table2.png\"\n        srcset=\"/static/0a340e681f1383cb2fcc7f57f041ea1f/12f09/table2.png 148w,\n/static/0a340e681f1383cb2fcc7f57f041ea1f/e4a3f/table2.png 295w,\n/static/0a340e681f1383cb2fcc7f57f041ea1f/fcda8/table2.png 590w,\n/static/0a340e681f1383cb2fcc7f57f041ea1f/efc66/table2.png 885w,\n/static/0a340e681f1383cb2fcc7f57f041ea1f/34e70/table2.png 1053w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\nfine-tuning을 위해 Dailydialogue, Switchboard, Cornell Movie의 세 가지 open-domain dialogue dataset을 사용.(450만 단어)(Appendix B참고)\nCCNEWS-100m data에서 BPE 학습 진행했으며 62k vocab 생성.</p>\n<h2 id=\"42-implementation\" style=\"position:relative;\"><a href=\"#42-implementation\" aria-label=\"42 implementation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4.2 Implementation</h2>\n<ul>\n<li>Fairseq toolkit 기반</li>\n<li>Adam optimizer</li>\n<li>lr: 0.0001</li>\n<li>batch: 2048</li>\n<li>inverse square root LR scheduler</li>\n<li>32 GPU, half-precision</li>\n<li>CCNEWS data 20 time swept</li>\n<li>더 학습가능 하지만 실질적인 이유로 중단</li>\n<li>dropout prob:0.1</li>\n<li>\n<p>fine-tune:</p>\n<ul>\n<li>2개의 gpu w/o float16 speed-up.</li>\n<li>validation set에서 PPL이 개선되지 않으면 learning rate를 절반으로 줄임.</li>\n<li>fine-tune에서 overfitting이 관찰되고 validation의 성능이 저하되기 시작하면 early-stop.</li>\n<li>tuned learning rate {1e-3,1e-4,1e-5}</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"5-experiment-results\" style=\"position:relative;\"><a href=\"#5-experiment-results\" aria-label=\"5 experiment results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. Experiment Results</h1>\n<ul>\n<li>standard dialogue model evalution에 대한 결과 제시.</li>\n<li>다양한 train strategy가 model의 행동을 어떻게 변화시키는지 상세한 분석을 함.</li>\n<li>중요한점은 model이 standard fine-tuning중에 language generation skill을 잊어 버렸는지, 그리고 mix-review가 model이 skill을 기억하는데 도움이 되는지에 대한 결정적인 질문에 답하는 것을 목표로 함.</li>\n</ul>\n<h2 id=\"51-standard-dialogue-model-evaluation\" style=\"position:relative;\"><a href=\"#51-standard-dialogue-model-evaluation\" aria-label=\"51 standard dialogue model evaluation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5.1 Standard Dialogue Model Evaluation</h2>\n<p>3가지 dialogue dataset에 대해 인간평가를 위해 Amazon mechanical Turk(AMT) 플랫폼을 사용.\nAMT 등급의 경우 각 turker에는 dialogue context와 임의의 순열세트인 model sample response set가 제공됨\nturker는유창성, 일관성 및 결합성에 따라 {-2, -1.0, 0, +1, +2}로 평가.\n2,500개의 평가를 진행하며 Top-k sampling을 사용하므로 BLEU는 사용하지 않음.</p>\n<p><strong>pre-train모델</strong>은 trained model from scratch 보다 ppl 기준 40%이상 개선되었음.\n<strong>NS pre-training</strong>은 MASS와 비교하여 7% 이상의 개선을 보여줌.\n<strong>NS pre-training</strong>이 contextual input을 더 잘 활용함.\n이 관찰에 기초하여 본 논문에서는 NS pre-training 분석에 대해 중점을 두고 진행.  </p>\n<p>standard fine-tuning과 비교하여 mix-review는 더 개선됨.\n이러한 이점은 강력한 regularization 효과 때문임.<br>\n그러나 mix-review와 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{\\theta}_{pre}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>) 간의 성능차이는 크지 않음.\nmix-review가 model의 generation 행동을 regularization하는데 너무 “공격적(aggressive)“일 수 있다고 추측하며, 보다 정교한 regularization 기법을 조사할 가치가 있음.(Section 6에서 진행)</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 45.94594594594595%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABZ0lEQVQoz2WS646CQAyFef/n8h8qoKyAgFyUm6IGgybq6tk5XYaY3SZDS2f42p7BeL/foJ3PZ8xmM0RRhDiOEW82SNMU6/UaURgiVIt57mdZhq7r0LYt9vs9brebMMgy+BiYmE5NTCYTbBSMAMKCwMdqtZLY933Ytq3ePYFXVYXucoFu6gP4m+CHpmkiSRIFCuB5noIEAvLUnq9yVVkKiN3T3+/3EUYzdMANy7JkEZYkqsthfBZwl0uJSwVsmkYkOh6PuPbXETh2SPt+PmHN52rsqVQn5FfDAHmeC4i6nU4nPB4PfNq/kV+vlyRCpZPruqKhFj8ePMfjIvCpiv+1sUOdINRxbLkUCu+6X+IXjoPFYqliSzTcbrcyct/3crv0nwWMuq5FjzzPZDTdHWOOnSmfZankuMqyQKN+ld1uh5T7Q/fMF0UBg7fHi4jjVERmAf1/sZPDoRXPHD/UMc/yTFlW49m6bvAD5QedCI3Vzj8AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table3\"\n        title=\"table3\"\n        src=\"/static/d8b73561b14baed99f7041aa24548e6d/fcda8/table3.png\"\n        srcset=\"/static/d8b73561b14baed99f7041aa24548e6d/12f09/table3.png 148w,\n/static/d8b73561b14baed99f7041aa24548e6d/e4a3f/table3.png 295w,\n/static/d8b73561b14baed99f7041aa24548e6d/fcda8/table3.png 590w,\n/static/d8b73561b14baed99f7041aa24548e6d/efc66/table3.png 885w,\n/static/d8b73561b14baed99f7041aa24548e6d/25c1c/table3.png 1047w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n표3 에서는 Dailydialogue testset에서 다른 model의 sample을 비교.  </p>\n<p>baseline model과 비교할때 pre-trained model의 response가 context와 더 관련이 있는것으로 나타났음.\n예를들어, 두 번째 response에서 baseline model은 “fruit cake”에 대해 말하고 pre-trained model은 이 대화의 주요 주제인 맥주에 대해서 말함.\n<strong>mix-review의 sample은 model이 “belgian ale”, “medium-batch”와 같은 정교한 단어로 맥주를 설명할 수 있다는 점이 흥미로움.</strong>\n이는 pre-training 동안 얻은 지식임.(belgian ale과 medium-batch는 Dailydialogue training data에는 존재하지 않음)</p>\n<h2 id=\"52-behavior-analysis-context-sensitivity\" style=\"position:relative;\"><a href=\"#52-behavior-analysis-context-sensitivity\" aria-label=\"52 behavior analysis context sensitivity permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5.2 Behavior Analysis: Context Sensitivity</h2>\n<p>context sensitivity는 NLG model의 중요한 속성임.\ncontext input을 왜곡하기 위해 두가지 방법을 사용.</p>\n<ol>\n<li>word-drop: context input에서 단어의 30%를 무작위로 drop</li>\n<li>word-shuffle: context input에서 단어를 무작위로 shuffle</li>\n</ol>\n<p>sensitivity를 정량화 하기위해 testset PPL의 상대적인 하락을 사용</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABXElEQVQozzVR2W7CQAzM//9PETwQiUs0B5AQkk029wHkKI1EP2BqW+3DKmvveDwzMfrnE2EYIlIKaZpiGAaM44jX64WmaaCiCNfrFXEcI9Eat9sNtmXBdhzkeY6Q3r3LBY7jYpwmGAU1N5sNnS1M08Rut4PjukJaFgXO5zP6vsf9fodLJPv9HovFhxCxgOPxiNVqhS3NsRiDN3NjvV4L4XK5hEl3y7ZFjUVqmKyqKhwOByFkkqqu4fu+1NxnFyzC+AcyyPlTwIo9zxdLQRAIsOs6IbCsT8FwrSim0+kkrjzPwzR9wei6lgYLaMqHLURkhTNlSzWp4Bwnyub5eMgCTRh+Z9VMmiSJ1FmWYWCFGQHathUwn4buVVmCs2UFvEz6RJxTpoyt6woF3UvCZVkqM1xrncLQtCHmQ8Pyt0kZb5XNlCHXSsVSc96cq1IRfQN6S/F+/2Cev8XFPM/4BZGr6/ajbnCdAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table4\"\n        title=\"table4\"\n        src=\"/static/e10a2078046d2e5e2777336e29cd4416/fcda8/table4.png\"\n        srcset=\"/static/e10a2078046d2e5e2777336e29cd4416/12f09/table4.png 148w,\n/static/e10a2078046d2e5e2777336e29cd4416/e4a3f/table4.png 295w,\n/static/e10a2078046d2e5e2777336e29cd4416/fcda8/table4.png 590w,\n/static/e10a2078046d2e5e2777336e29cd4416/efc66/table4.png 885w,\n/static/e10a2078046d2e5e2777336e29cd4416/1c1a4/table4.png 1046w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>scratch부터 training된 model이 상대적으로 둔감하다는것을 관찰.\nstandard pretrain-finetune process가 있는 model은 훨씬 더 민감하여 pre-train이 model의 동작을 효과적으로 변경함을 보여줌.\nNS pre-train model은 MASS와 비교하여 더 나은 context을 제공하며, 이는 우수한 performance로 설명됨(section 5.1)</p>\n<p>놀랍게도 NS pre-trained dialogue model은 fine-tune없이 pre-trained model보다 context input에 덜 민감.\n이것은 3.2절의 model이 standard fine-tuning동안 중요한 generation skill을 잊어버렸다는것을 의미.\n또한 <strong>mix-review fine-tune strategy이 문제를 효과적으로 완화</strong>할 수 있음을 발견.\nsensitivity는 fine-tuning보다 훨씬 높으며 pre-trained model에 가까움.</p>\n<h2 id=\"53-behavior-analysis-knowledge-transfer\" style=\"position:relative;\"><a href=\"#53-behavior-analysis-knowledge-transfer\" aria-label=\"53 behavior analysis knowledge transfer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5.3 Behavior Analysis: Knowledge Transfer</h2>\n<p>3.1에서 논의된 바와 같이, 이상적으로 이 model은 large-scale pretraining data로부터 “knowledge”를 회득할 수 있으며, 이는 downstream open-domain dialogue task에 유용할것임.\n이 section에서는 model의 knowledge의 양을 정량화하는 precoess를 설계하고 이를 사용하여 pretrain-finetune framework가 model의 동작을 어떻게 변경하는지 모니터링 함.</p>\n<p>pre-training CCNEWS data는 public news domain에 있으므로 model에 “big news”에 대한 knowledge가 있어야 함.\n따라서 365개의 trend 용어(e.g., iPhone7, Deadpool, etc.)가 포함된 2016년 Google trend data를 활용함.</p>\n<p>model에 특정 용어에 대한 knowledge가 있는지 query하기 위해 knowledge term과 관련된 response를 generation하도록 model을 trigger하는 3개의 뉴스 스타일과 3개의 대화 스타일 “trigger templates”를 설계.\n각 트리거에 대해 10개의 샘플을 수집한 다음 참조 설명에 대해 generation된 샘플의 BLEU 점수를 계산.  </p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 56.08108108108109%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB6ElEQVQoz0VT547iYAzM+z/R7U/gINSQAiQklBTQ0ntnYc5jDjbSyJ+My3hsDN/voFqtol6vo1DII4oiTCYTjEYjTKczbDYbsVMUi0WY5bLGlsWWyybSNMPk+xvL5RKr1QqHwwFGHMdot9sKz/PgOg6azSbiOMHPzwP8zqcTrEYDrVYLruvCtm00LQuWYDweS9wP3p9BZ6FQQK1WExZ/P2/6u92uMqb1fV/tCyE6QoANOp0OsizTwpfLBQYDHdvRrgzwgwBJmqLf70uRQAsweD6fY7FYfMajpRxz8XHU5/OpMDzPRUPYcGSOE0U9TRwOh1q01+upJVO+wzBEkiTK5na7KR6Px+/IpVIJf76+VPRcLod8Pg/HcWGKn+JXKhWYpolGw5J3FZbo+9bvTUI1Ff92u4VBDer1miZWBQzwZPS3BG9wWZ+3xLBAEHRl06lexfl8VqYGzyX/fxG2BNmSOBgMtDubcUwmzGYzBVkw+SSbp6V+1+v1d+QgkKVIEWpG8cMwUo0o+H6/x263w3q9VnARh+NRz4S43+8fy6J8GwMRPMtGH9F7vQh9YchR0jRBLMV5q7E05CEnSaxxbE4Sg0FfY3kNvASDG+QPTOIPTKQ2vC36mEz/q9mrECUhMvGTCP9VPKWjsP8H0/EZYs9vjNIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table5\"\n        title=\"table5\"\n        src=\"/static/82aaecb18621a97ecd419499f10d3920/fcda8/table5.png\"\n        srcset=\"/static/82aaecb18621a97ecd419499f10d3920/12f09/table5.png 148w,\n/static/82aaecb18621a97ecd419499f10d3920/e4a3f/table5.png 295w,\n/static/82aaecb18621a97ecd419499f10d3920/fcda8/table5.png 590w,\n/static/82aaecb18621a97ecd419499f10d3920/efc66/table5.png 885w,\n/static/82aaecb18621a97ecd419499f10d3920/34e70/table5.png 1053w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34.45945945945946%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABWElEQVQozzVR246CUAzk/z9HE8n6ohEQIaJRkJtyXQgiIJDsPs+23d2Hcs7pdKZlqjRNA45hGNC2LYqikDMMQxi6Dl03EMcxuq5DXdcoy188SRIYhgHLspCmKV6vl+go/u0G27apsBQCg8fjkYR0nE4OrlcXmrbDdruVe5alIiL4+Yzr5ULCOjabDVzXg8JkVVVFpCw/kec5EQ5YrVTc73cJXdOwXC5xITL/gbbbCSeMIpmexRaLBVyPBD36aESwLBuPx0MI1uGA9XqNG03Pgo7jYL834fu+4KZpEv4hYnEc/eF7aaCUVJBlmQT7UlU1giCQqKpKbGCRf0s4uI6bM87BGFvVko8Km8wL4KKMkjwRd+Z3mibSlYv5zcFTZlku1jAvCHwZJqB883xCiYgQEMCFnudS5wJ918vWp2mke4e+H2TL8zxjHEfB5mmifI/3+y05Pr++vvEDf9nvQMUcMq4AAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table6\"\n        title=\"table6\"\n        src=\"/static/08916316f3b86c04ba128d9165694d9e/fcda8/table6.png\"\n        srcset=\"/static/08916316f3b86c04ba128d9165694d9e/12f09/table6.png 148w,\n/static/08916316f3b86c04ba128d9165694d9e/e4a3f/table6.png 295w,\n/static/08916316f3b86c04ba128d9165694d9e/fcda8/table6.png 590w,\n/static/08916316f3b86c04ba128d9165694d9e/efc66/table6.png 885w,\n/static/08916316f3b86c04ba128d9165694d9e/d53ff/table6.png 1068w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>뉴스 트리거에 대해 pre-trained model의 점수와 대화 트리거에 대한 다른 대화 점수를 비교해야한다.\n먼저 pre-trained model을 관찰. 뉴스 스타일 트리거는 대화 스타일 트리거보다 훨씬 더 관련성이 높은 결과를 얻을 수 있음.\npre-trained model에는 뉴스 데이터가 포함되어 있기 때문에 이는 직감과 일치하다.  </p>\n<p>fine-tuned model은 baseline model보다 knowledge가 풍부하지만 pre-trained model보다 점수가 훨씬 낮음.\ncontext sensitivity의 경우와 마찬가지로 standard fine-tune의 forgetting problem을 다시 보여줌.</p>\n<p>mix-review와 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)가 pre-train 과정에서 얻은 knowledge를 효과적으로 유지하면서 standard fine-tune model보다 훨씬 높은 BLEU 점수를 얻음을 확인.\nmix-review는 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)보다 높은 BLEU점수를 보여주므로 knowledge 보유에 있어 더 우수함을 보여줌.  </p>\n<p>표5에 다양한 모델을 샘플을 소개함. 공간을 절약하기 위해 각 knowledge 용어에 대해 30개의 샘플 중에서 가장 관련성이 높은 샘플을 수동으로 선택하여 표시.\n관측 결과는 정량적 결과와 일치: <strong>standard fine-tuning은 knowledge 용어에 대한 자세한 정보를 잃어버리고 mix-review는 model이 이를 유지하는데 도움을 준다.</strong>  </p>\n<p>더 중요한 것은 <strong>model이 dialogue에서 knowledge를 표현할 수 있다는 것이다.</strong></p>\n<h1 id=\"6-implication-and-discussion\" style=\"position:relative;\"><a href=\"#6-implication-and-discussion\" aria-label=\"6 implication and discussion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. Implication and Discussion</h1>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 58.78378378378378%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAABY0lEQVQoz6WT646CMBCFef/Xwz9quAgIiJcFCy2l0LMzaA1mXd1kSyZtJ+3XmTODBxrWWp4wjiOUUuj7/jEvjX1sWmtcLhpV1dEdgyXDW27c4U/DWI22s4iikYDD70CGOSD7nsydUz2SOoU0LQY9YRjeAF1qSyAczBjY0wmWsrAuUjPAfAI+Irxfsstc74+5wZr/PcJpukVGD3R1jX1RoDwckOc5Clofj8fZjHlTFL0Ens+weYGJvuv1C3EcIwrD2xxFkFLOttT8RYQaUjWQGLnkQCdALoqkIVCI9Xo9w4IgQNM0mCiLH8CH+HPbUK/JFopaQRkJTlq1AvtkB3+1worM931sNhvqw8uz5q+ALHLbtqjrhrpDQ1wFBAFb2eFMEnCKHJkQYi4GQ1lDvs/R8uy5ijnof4cXktBlWdJvdACvkyRBTDqlaTpXNNvvyR/MfvaxbbdbZFl2O0tF2pHxvqoqfANdoKYXpOHYhAAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig2\"\n        title=\"fig2\"\n        src=\"/static/73f7eba7653cbd590752d1b65e0f622c/fcda8/fig2.png\"\n        srcset=\"/static/73f7eba7653cbd590752d1b65e0f622c/12f09/fig2.png 148w,\n/static/73f7eba7653cbd590752d1b65e0f622c/e4a3f/fig2.png 295w,\n/static/73f7eba7653cbd590752d1b65e0f622c/fcda8/fig2.png 590w,\n/static/73f7eba7653cbd590752d1b65e0f622c/9f82e/fig2.png 820w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<p>그림 2에서는 function space의 model에 대한 UMAP projection을 보여줌.(세부사항 및 추가도표 append E)\nstandard fine-tuned model은 pre-trained model의 군집에 가깝지 않으므로 model의 generation 동작이 pre-trained model과 실질적으로 다르다.  </p>\n<p>mix-review는 fine-tuning process를 regularization하여 model의 generation 동작을 pre-trained model에 가깝게 유지함.\n이러한 관찰은 sec 5.2, 5.3결과와 일치함.</p>\n<p>mix-review는 너무 “aggressive”일 수 있으며 target task에 충분한 attention을 하지 않음.\n반면 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)는 model의 generation 행동을 regularization하는데 충분하지 않음.(Appendix E 추가설명)</p>\n<p>open-domain dialogue task관점에서, dialogue context에 대한 sensitivity와 pre-train으로부터 knowledge를 transfer할 수 있는 능력은 data중심의 knowledge가 풍부한 대화로 이어질 수 있는 가능성을 열어줌.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 51.35135135135135%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAABuElEQVQoz1VSi46iQBDk/7/qVmN8RNBDXqIoDwVRd9XTGBW0rqtvMXsknRlmumuqqtvYbDYYjUbIsgyLxQLLZYz1eo3tdovH4yFxR+D7cBxX7pYSC8xmM/hBgNVqhaqqcL/fNeq6hpEmCT4+fmkCi5h0OBxwvV7RfOZwiE6nI0AhPAH3PBfj8Vhjv//Ez8/Ihc1gMEAURZhOp8qOoMfj8Z1k27+1mCqmYYj5fI7dbidge5zPZ815vV4aRpHnsCxT5cZxgkiSKYksWXS5XOALK9ueYCGPhgIYx7ES4Pnn19f/gIlIphzP8zQcx1E2pmmqt2E4Q7/f1yDAZDKB67oKShKspxo+TB+NstzI67bKYIGvDXAQBL5aYFkWut2ugtA/V+54TsA8L5CmqTaL8uv6KU1JE/R6PfWRayDNaSRp17XzS3Aa2PnGu1ys4n9Zlrq+GWZZKgx66g0lDqWjBG+322i1Wm+pLLrdbjomHCeuVdWsld49n08CZt/z9S8ITJb6/82UssiQ9vxkupXgyrOiKLRBBmWRfhTNkUjhapWpn2maKRD3ND6Ol7pnA/7IqFBiEzzjVJxOJ/wFbLXajywYYpgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table7\"\n        title=\"table7\"\n        src=\"/static/a9fbf494c5e978840ae0e75ab82a6ba7/fcda8/table7.png\"\n        srcset=\"/static/a9fbf494c5e978840ae0e75ab82a6ba7/12f09/table7.png 148w,\n/static/a9fbf494c5e978840ae0e75ab82a6ba7/e4a3f/table7.png 295w,\n/static/a9fbf494c5e978840ae0e75ab82a6ba7/fcda8/table7.png 590w,\n/static/a9fbf494c5e978840ae0e75ab82a6ba7/efc66/table7.png 885w,\n/static/a9fbf494c5e978840ae0e75ab82a6ba7/8f0f9/table7.png 1045w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n표7에서 mix-review에 의해 train된 model과의 multi-turn 및 single-turn 상호작용 예를 보여줌.\n증명하고자 하는 목적으로 single-turn 예제를 위해 model에서 10개의 샘플 중 가장 흥미로운 응답을 수동으로 선택.\nmodel이 pre-train 과정에서 얻은 knowledge로 흥미로운 response를 보여줄 수 있음을 관찰.\n흥미롭게도 own “opinions”을 개발하여 사용자에게 조언을 제공할 수 있음.</p>\n<p>마지막으로, open-domain dialogue model의 악의적인 response problem에 대해 논의.\nHe&#x26;Glass(2019a)에서 알 수 있듯이 악의적인 response를 출력하기 위해 scratch 부터 train된 dialogue model을 트리거하는 것은 상대적으로 어려움.\n그러나 표7에서 볼 수 있듯이 pre-trained model은 “provoked(도발)“될 때 악의적인 방식으로 쉽게 반응하도록 트리거됨.\npre-trained model은 baseline model과 비교하여 contextual input에 더 민감하여 control하기 쉽기 때문.\n이로인해 악의적인 response problem이 보다 관련성 높은 문제가 됨.</p>\n<h1 id=\"7-related-works\" style=\"position:relative;\"><a href=\"#7-related-works\" aria-label=\"7 related works permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>7. Related Works</h1>\n<h3 id=\"forgetting\" style=\"position:relative;\"><a href=\"#forgetting\" aria-label=\"forgetting permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Forgetting</h3>\n<ul>\n<li>3.2절에서 논의된 바의 같이, sequential learning의 “catastrophic forgetting” problem과 대조적으로 pre-train data의 성능 저하가 반드시 나쁘지는 않음.</li>\n<li>NLP pretrain-finetune framework 5.2, 5.3절에서는 standard fine-tuning 중에 중요한 language generation skill을 “forgetting”하는 것을 확인.</li>\n<li>제안된 mix-review strategy는 sequencial learning의 pseudo-rehearsal algorithm과 유사하지만, 우리는 여전히 pre-train data에 접근할 수 있다고 가정.</li>\n<li>mix-review는 NMT, speech recognition, OCR에 유용한 것으로 입증된 multi-task learning의 형태로 볼 수도 있음</li>\n<li>그러나 이러한 작업은 주로 supervised task에 중점을 둠.</li>\n<li>본 연구는 unsupervised pretrain-finetune 과정에서 NLG model의 forgetting problem을 분석하고 data mixing개념을 사용하여 해결하는 첫 번째 연구임.</li>\n</ul>\n<h3 id=\"pre-training-for-nlg-models\" style=\"position:relative;\"><a href=\"#pre-training-for-nlg-models\" aria-label=\"pre training for nlg models permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Pre-training for NLG Models</h3>\n<ul>\n<li>NLG model에 대한 unsupervised pre-training은 최근 많은 연구 관심을 받았지만 어떻게 pre-train이 neural language generator의 동작을 변화시키는지는 잘 이해하지 못했음.</li>\n<li>여러 연구에 따르면 large-scale training은 LM common-sense knowledge를 가르치는것으로 나타났음.</li>\n<li>반면 knowledge-grounded chat-bots은 dialogue model에서 중요한 주제였음.</li>\n<li>이러한 연구에는 일반적으로 model에 관한 정보를 제공하기위한 추가 retrieval module이 포함됨.</li>\n<li>이러한 연구와 달리, 우리는 fine-tuning이 large-scale pre-training 동안 얻은 knowledge를 보존하는지 여부를 연구.</li>\n</ul>\n<h1 id=\"8-conclusion\" style=\"position:relative;\"><a href=\"#8-conclusion\" aria-label=\"8 conclusion permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>8. Conclusion</h1>\n<p>본 연구에서는 language generation 관점에서 standard NLP pretrain-finetune framework의 forgetting problem을 분석.\n“data mixing”이라는 concept를 채택하고 mix-review fine-tuning strategy를 제안.\nmix-review가 model이 pre-train 과정에서 배운 중요한 <strong>language generation skill을 효과적으로 기억</strong>하는데 도움이 될 수 있음을 보여줌.</p>\n<p>자세한 행동 분석을 통해 standard metric의 성능 향상에 따라 large-scale pre-train을 통해 model의 generation 행동이 다양한 심오한 방식(e.g., context sensitivity)으로 변경됨.\n더 중요한 것은 fine-tuning data가 news(Dailydialogue)에 관한것이 아닌 경우에도 dialogue 결과 model로 news를 논의할 수 있음을 보여줌.\n이를 통해 language generator를 사용자 정의할 수 있는 완전한 data 중심적인 방식의 흥미로운 가능성이 열림.</p>\n<h1 id=\"appendix\" style=\"position:relative;\"><a href=\"#appendix\" aria-label=\"appendix permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Appendix</h1>\n<h2 id=\"a-beam-search-vs-top-k-sampling\" style=\"position:relative;\"><a href=\"#a-beam-search-vs-top-k-sampling\" aria-label=\"a beam search vs top k sampling permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A. Beam-search VS. Top-k Sampling</h2>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 26.351351351351354%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAYAAABFA8wzAAAACXBIWXMAAAsTAAALEwEAmpwYAAABHklEQVQY0yWQW4+CQAyF/f8/SBJBIBIFEXAJxgjIJV4YBgVW3ScgOdsZH04mbaen7TcbhgH3+x3P5xOfzx/e7zeqqkJRFLAsC77vY7lc4ng8om1b1HUNz/OwWq3gOA4URcF6vcH1esU4jpiN4wDTNKU8aj6dTnBdF4vFAqqqIU1TmIYJXdex3/+Q9lDmc1nb0T9NVaFqmhw+TRNmE7natg3DMGBQU3Q4SFNvt8N6YyM7n+EHgdwqiiIcqO66W+px5PYB1QIaEobh11CcLLYQJk3ToOs6ZFmGMxnFcYzL5SLflOKyLCUK8T9JEimRE8rz/HsyI151zdH3PW63GzjnFDMwYvV4NMSTEbtO5itizXkjayIW7IUEV8YYfl8v/AMIrmK9o4i7zQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table8\"\n        title=\"table8\"\n        src=\"/static/fd3319204991cf571aa9002b9e851b44/fcda8/table8.png\"\n        srcset=\"/static/fd3319204991cf571aa9002b9e851b44/12f09/table8.png 148w,\n/static/fd3319204991cf571aa9002b9e851b44/e4a3f/table8.png 295w,\n/static/fd3319204991cf571aa9002b9e851b44/fcda8/table8.png 590w,\n/static/fd3319204991cf571aa9002b9e851b44/77800/table8.png 855w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\nbeam-search를 top-k sampling과 비교하기 위해, 다른 절차에 의해 train된 model의 sample에 대한 다양한 metric을 계산.\ntop-k sampling으로 제공되는 response는 beam-search보다 훨씬 다양함.\nbeam-search는 “generic response” problem으로 인해 많은 어려움을 겪고 있음.  </p>\n<p>예를 들어 response의 34%가 switchboard에서 “um-hum”이다.\n또한 multi-turn dialogue 실험에서 beam-search는 반복적인 response를 제공할 가능성이 있음.  </p>\n<p>마지막으로, 수동 검사를 통해 top-k sampling의 sample quality가 저하되지 않는 것으로 나타났음.\n이러한 관찰로 인해 이 task의 주요 decoding method로 top-k sampling을 채택.</p>\n<h2 id=\"b-details-on-data-sets\" style=\"position:relative;\"><a href=\"#b-details-on-data-sets\" aria-label=\"b details on data sets permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>B. Details on Data-sets</h2>\n<p>Dailydialogue는 고품질 multi-turn dialogue dataset.\n사람이 직접 작성했고 noise가 적다.\ndataset의 dialogue는 일상적인 의사소통을 반영하고 일상생활에 대한 다양한 주제를 다룸.\ntraining split에는 약 11k의 dialogue(130만 단어)가 있으며, val 및 test set에는 모두 1k개의 대화(0.1백만 단어)가 있음.  </p>\n<p>Switchboard Dialogue Act Corpus3은 utterance-level의 dialogue act로 주석이 달린 two-side telephone conversation 모음인 Switchboard Telephone Speech Corpus의 버전.\n이 작업에서는 data의 dialogue text 부분만 사용하고 training을 위해 1.1k dialogue(181k문장/120만 단어), validation을 위해 50 dialogues, test를 위해 50 dialogues를 사용.</p>\n<p>Cornell Movie Dialogue Corpus4는 영화 대본 모음집이다.\ndata를 처리할 때 영화의 전체 script를 long dialogue로 간주.\ntraining split에는 9k개의 대화(450만 단어), val 및 test에는 180개의 dialogue(8만5천 단어)가 있음.</p>\n<h2 id=\"c-model-samples\" style=\"position:relative;\"><a href=\"#c-model-samples\" aria-label=\"c model samples permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>C. Model Samples</h2>\n<ul>\n<li>표 9에 세 가지 dialogue dataset에 대해 서로 다른 training procedure의 sample이 나와 있음.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 141.89189189189187%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAcCAYAAABh2p9gAAAACXBIWXMAAAsTAAALEwEAmpwYAAADzElEQVRIx5VVa1PiUAzt//8/rjqr+8FBQRaG8iiFAgXKG0p5yauo2Zxc0lVXZ9zOZG5vuTfJOTkJVtv36ebmJ9l2kZrNJtVqNfL9FjlOlWquS41GQ1b8Np/PKZzNaMoWRRHNplNjvN/tdnQ8Hsk6nWKqVCpyodHwyOXLcOp5njiOooU4Wq/XxglfnoUhLRYLeV/yOplM6OnpifBY+/2OyuWyOFGHvt+Ww2E4o/FkSlO+EEVzmnA2uDwejyUIAszDuWR3OByMw5jTLBQKZBeL4hQOq9WqQK1WHXL4HQEdx5Gs8b1cKpHfbrOzUAKvVivSx9psNpTL/aYGQ4azInPp8aVWq2U45W/1el0MgRRJu9PhTCfU7/cZiaHgdDqRNRgMKJNJJxlIho7JzPPqwm8Q9Ajner0eDYdDtgH1eQ/4vV7A8CPmcEsvLy9k7bZbyudyVGVHyMqTTBzOyJMMAWe73bFtab/fSyXBGQzodI3j2EDe7baUSaepxLy0mRdAM1Wuy340Gksmo9FIsoQB5pwLApjISp/X11dTlHw+L4581qTIhR35nK1y5rpVyb5WqwsloAf8ffZYIP36+oqy2awcNFU2la6c9+CxUinLd1S8VComnHe4OFOWExAsl0uyZrMp/bq9lcO2XaBuN5ADIB/wgiBgHtfCoRpErNzhHfyBW6nyiTfIzj3z5ro10RaEK93AzrGiU3AZ62KxZGcchJ3+AxmXURSkj6yiM9nPz89COKKq4dvbbLDXYqhZG474mMmImFFVkA1YG8lmRUuWDaSDzLCCJ80Ue+1hOJMMEc22baNBryGwtV9NP5v2GvO36bmXsYZMCQqBBI7H+G+GSBsOIRsUAPpChsfjQeABGoKi+bGq4Z46ecdhq9WkHxcX9PDwIJKAwTmGAHQJQ9foYEAfo4NULmpAJLJp8qGry0vu5wwPBlsuApap5kIMB2G6V4MS1EANZMSQTzK+wCEgozBoLTj8COc7j4VK6bTpdrsSDRxCMt91+E426JT7+5RUuCMzbpzIRGGKqBmOQlMacA5/ByhcMhxQsTQLG707HI6SyQL4QdBNJgwuo+qo7kdTJOJwxZGy2UepJIbAYDCUuQeCIXrAXy6NwLUzvoKdtN7d3Z1UV8f+2z+iOD59yddnZh1ZsKlUSiCj/VxeHaciWsToQsD/KbYFkjFtMLHd8x8SONTxpZmK8dkwNKsWKJlKHBjFs/r8x9Nj3XVYf5ANOgPVxoo93rVDQAkmeZMNegU9OIc/LwQH9xZI11m30fU8OPUdphPo7e/yTd434gzPH1STLRkUO3nTAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table9\"\n        title=\"table9\"\n        src=\"/static/af40c0414363bfe61da4fbf18c57ffbb/fcda8/table9.png\"\n        srcset=\"/static/af40c0414363bfe61da4fbf18c57ffbb/12f09/table9.png 148w,\n/static/af40c0414363bfe61da4fbf18c57ffbb/e4a3f/table9.png 295w,\n/static/af40c0414363bfe61da4fbf18c57ffbb/fcda8/table9.png 590w,\n/static/af40c0414363bfe61da4fbf18c57ffbb/d0d8c/table9.png 609w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<h2 id=\"d-supplementary-experiment-results\" style=\"position:relative;\"><a href=\"#d-supplementary-experiment-results\" aria-label=\"d supplementary experiment results permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>D. Supplementary Experiment Results</h2>\n<ul>\n<li>이 section에서는 space limit으로 인해 본체에서 지연되는 결과를 보완.</li>\n<li>표 10에는 AMT 등급의 유창성/일관성/강도 점수가 나와있음.</li>\n</ul>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 35.13513513513513%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABa0lEQVQoz11R2W7CQAzM//9MaQ5yCELCkZAAIQm5WwKVOEUkeOMFaep1pT6wkuW1PV6Pd6TD4YDlcomiKFDXDW63Gy6XC87nM47HE+I4pnyNPM8RrVaIoohzWZYhSRLs9z+Mv16vuN/vkETBsiwGnE4n7Hc7TCYTyLIMRVGg9fvYbDYI5nOoFH/0eoyP4wTT6ZQxpmliMBigbVtIOT2kaRpGoxFWxKAsSy4OhzYsAprU7HkefN/jnG3b5AcU+/ApL7CO48LQdRTUK31/NQiDAI7rIiUmgqU3m8Gjhhn5OTETg9a0qriHYUgW8NrrdcSYxWKBgN5o2x2khAqapkLXDS6maUp3HTKtYhgGr2cTe9dxoKoqm6iPx2Nm+0lfIL5FUWT6thySECXPM9TNnyCCYVVVaCgWXoghRKnrioUripJ9RTmBKcsC7XaLjHCH4xES3s7z+WSFH48Huu72r6AwMbDrOq6Jwa/X670dvyNV42wm78TlAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table10\"\n        title=\"table10\"\n        src=\"/static/29099a6fe185076384cef901f2d242a7/fcda8/table10.png\"\n        srcset=\"/static/29099a6fe185076384cef901f2d242a7/12f09/table10.png 148w,\n/static/29099a6fe185076384cef901f2d242a7/e4a3f/table10.png 295w,\n/static/29099a6fe185076384cef901f2d242a7/fcda8/table10.png 590w,\n/static/29099a6fe185076384cef901f2d242a7/cc8d6/table10.png 791w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>표 11에는 Switchboard 및 Cornell Movie dataset에 대한 context sensitivity 결과가 나와 있음.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 48.64864864864865%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB5ElEQVQozz1S2ZKiQBDk/7/HnVhXRfBAAS8WT0BuDc9VI2Z8zamsjd2Hprupyqys7DKezyc26zXWsuI4xvF4xPV6xf1+R13X+n+5XGosiiKEYQjXdTGZTJDlucbns5n883A6nWCURYFOp6Or3e7AlH0wGPxPHA6HWK3WCIIF+v0+Wq0WGo0Gho4D3/ME00az+RM/Pj4UY5DVtm30ejYs2S2rC2c0wmaz0bVYLPB6vXA+n+H7vqqbTme43W7Y7/dafDqdSO5WuvoDgy3atoVut6vJTGg2fyl4Ke2Nx2McJCcVsO97cOVu2z0loyLT7KhyYuv68JeQJPzJnQSz2VyqTkXdHK60RS9JQCW0oCe5WZZhJd4OBWOaJjwRcDiQUD70z7YsadeGI97wEdjidrtVAp6rqtQzizrOSMEbVWiqiCAIcJI8gwF6SOkj8Y7EE1FH5XwIElSiMEkSAY7E656S8B6Gv9GXO/0fS8tVVcPg2FAJ/fi38zE4NiRla4/HU0cpSWLsdjsdn8vlonGe+XDcH48HDM4X2yEwjiOkaYqdBCMBEpyId7Hc8yzXgowXMmosupczlaZphrIsEQmXepjnhf6k8VVV6WvleaZgFirLQttmS7znMtBFUWru5+cX3m+uN75kfQNttbpIuwyR+AAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table11\"\n        title=\"table11\"\n        src=\"/static/6ef2c1694846b676aa0f5a152cc2bc23/fcda8/table11.png\"\n        srcset=\"/static/6ef2c1694846b676aa0f5a152cc2bc23/12f09/table11.png 148w,\n/static/6ef2c1694846b676aa0f5a152cc2bc23/e4a3f/table11.png 295w,\n/static/6ef2c1694846b676aa0f5a152cc2bc23/fcda8/table11.png 590w,\n/static/6ef2c1694846b676aa0f5a152cc2bc23/efc66/table11.png 885w,\n/static/6ef2c1694846b676aa0f5a152cc2bc23/cc488/table11.png 928w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></li>\n<li>표 12에는 Cornell Movie dataset에 대한 knowledge transfer 결과가 나와 있음.\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 33.78378378378378%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsTAAALEwEAmpwYAAABNklEQVQoz21Ra2+CQBDk//8dU4r9QBGFWCPSqgE5HueDh/rBryYITG+30YjpJZNhyd7s3KzWdR0IdE6nE7Isw+FwQFmWSJIEQgjs93vEsYBt2/AWC+R5Diklttvt4+6dtWdBEplMJthsNtjtdiiKEr7vw3VdjMdj/CyXmM1mcFTPcPiBMAwfYv8K0lTDMGBZFotSvVQiuv6m/n1CKkdf0yn3DAYDBEHQEyRoz3bpabY9gmma7Owu+K7rcB0HaSYxn8+VYwfWaMRDX4/WNC1/NE2Dy+WCNE0ZJHY+nzkGEg3DgGvKlwZTD2V+u90YdV0za57nYb1e41s5Wq1W/AziKIogFKim5VAtZfbIl0ALoxzjOGYNIWJotDFyQdP/HBWoqkrhyFwUBY6Kc8XX61W5qHuO2rbt4RdB8gAtY9XARwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table12\"\n        title=\"table12\"\n        src=\"/static/ef635f34652e5ad7bd931adf2abeaaa8/fcda8/table12.png\"\n        srcset=\"/static/ef635f34652e5ad7bd931adf2abeaaa8/12f09/table12.png 148w,\n/static/ef635f34652e5ad7bd931adf2abeaaa8/e4a3f/table12.png 295w,\n/static/ef635f34652e5ad7bd931adf2abeaaa8/fcda8/table12.png 590w,\n/static/ef635f34652e5ad7bd931adf2abeaaa8/efc66/table12.png 885w,\n/static/ef635f34652e5ad7bd931adf2abeaaa8/f6f78/table12.png 932w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></li>\n</ul>\n<h2 id=\"e-details-and-auxiliary-plots-of-umap-projection\" style=\"position:relative;\"><a href=\"#e-details-and-auxiliary-plots-of-umap-projection\" aria-label=\"e details and auxiliary plots of umap projection permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>E. Details and Auxiliary Plots of UMAP Projection</h2>\n<p>function space projection의 경우 UMAP에 대한 input은 model의 output distribution이여야 한다.\nCCNEWS validation set 및 Dailiydialogue validation set에 대해 10k 단어로 model의 ouput distribution을 수집 (따라서 두 개의 긴 vector가 concat됨)\npython UMAP의 기본 hyperparam을 사용.\nCCNEWS data를 pre-train하는 동안 20epoch가 하나의 전체 data pass.<br>\npre-train checkpoint의 epoch 100, 200, 300, 400, 500 에서 fine-tuning 진행.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 590px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 81.75675675675677%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsTAAALEwEAmpwYAAABqUlEQVQ4y61U2ZLiMAzk/38QeIHiDsR2SOLYOeltCRLYnWWYhxGlkhxbbaklM7vdbhARW1UVmqZB27Zo2mbyfRXgsuy592JjjFO8yGx0hmFAURT4KgNs7mCs0TP/Sl3X7wHzPJ82YhORF1z3PUpzQXwESmaiI8hbwLHkxxKh9jhby5Jq3Fhymd/Bq9MJmcs+A95LLrkxaHYtualIQUeQZ/GAyQwB3VT+W8Cegcoh1558OWZypY6A47m8uqL05Q8zLHmQyzw5stx0yuyVllf5DEietAz63nsMzE72/6c/bwq+FwXkTxL4mKGOTWB3z2dst1scDge1J3J5uVym4JbNq2P4PIcZX0PkjAnIYrHAfD5Xu9vtdPb6R4NclmK73yNJPAHj+5KFt1B0muFms8F6vcbxeMSewf3L+MQ28FLLiwqEUD2poP41NpJheTVYrVaa2XK5VE2ShIFB327XdYgc+MxFGBPIu/8KOD038iKjI5lKg0TFlz+AcS1+UBv0EtGxQQqIX5aZMXwVfEqiaZrSWljrWOZJ1/dv933h1rFc+Sa+pW/oC4aoVPMHrTjhKfeZIIIAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig3\"\n        title=\"fig3\"\n        src=\"/static/6ee68faa4419d3fc04cb24edc4c51b5a/fcda8/fig3.png\"\n        srcset=\"/static/6ee68faa4419d3fc04cb24edc4c51b5a/12f09/fig3.png 148w,\n/static/6ee68faa4419d3fc04cb24edc4c51b5a/e4a3f/fig3.png 295w,\n/static/6ee68faa4419d3fc04cb24edc4c51b5a/fcda8/fig3.png 590w,\n/static/6ee68faa4419d3fc04cb24edc4c51b5a/94829/fig3.png 878w\"\n        sizes=\"(max-width: 590px) 100vw, 590px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>\n<ul>\n<li>그림 3에서는 동일한 model set에 대한 parameter space UMAP projection을 보여줌.</li>\n<li>UMAP에 대한 input은 transformer model의 flattened weight matrix를 concat.</li>\n<li>중요한 점은 fine-tuned model이 일반적으로 starting point(pretrained models)에 매우 가깝다는 것.</li>\n<li>그러나 그림2와 매우 다르다. 이는 WD(<span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><msub><mi>θ</mi><mrow><mi>p</mi><mi>r</mi><mi>e</mi></mrow></msub></mrow><annotation encoding=\"application/x-tex\">{ \\theta  }_{ pre }</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.980548em;vertical-align:-0.286108em;\"></span><span class=\"mord\"><span class=\"mord\"><span class=\"mord mathdefault\" style=\"margin-right:0.02778em;\">θ</span></span><span class=\"msupsub\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.15139200000000003em;\"><span style=\"top:-2.5500000000000003em;margin-right:0.05em;\"><span class=\"pstrut\" style=\"height:2.7em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord mathdefault mtight\">p</span><span class=\"mord mathdefault mtight\" style=\"margin-right:0.02778em;\">r</span><span class=\"mord mathdefault mtight\">e</span></span></span></span></span><span class=\"vlist-s\">​</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.286108em;\"><span></span></span></span></span></span></span></span></span></span>)와 같은 parameter space regularization이 model의 regularization에 효과적이지 않을 수 있음을 나타냄.</li>\n</ul>","frontmatter":{"title":"[논문리뷰] Mix-review: Alleviate Forgetting in the Pretrain-Finetune Framework for Neural Language Generation Models","date":"October 16, 2019"}}},"pageContext":{"slug":"/NLP/mixreview/","previous":{"fields":{"slug":"/NLP/plato/"},"frontmatter":{"title":"[논문리뷰] PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable","category":"NLP","draft":false}},"next":{"fields":{"slug":"/NLP/electra/"},"frontmatter":{"title":"[논문리뷰] ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators","category":"NLP","draft":false}}}},"staticQueryHashes":["3128451518","96099027"]}