{"componentChunkName":"component---src-templates-blog-post-js","path":"/NLP/spdf/","result":{"data":{"site":{"siteMetadata":{"title":"Deep Learner","author":"[Jeonsworld]","siteUrl":"https:jeonsworld.github.io","comment":{"disqusShortName":"","utterances":"jeonsworld/blog-comment"},"sponsor":{"buyMeACoffeeId":""}}},"markdownRemark":{"id":"a59b2153-0b18-5f83-ac03-38fd50a74825","excerpt":"SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models\nVithursan Thangarasa, Abhay Gupta, William Marshall, Tianda Li, Kevin Leong, Dennis DeCoste, Sean Lie, Shreyas Saxena\nhttps://arxiv.org/abs/2303.10464 최근 NLP에서는 Pre-training과 Fine-tuning…","html":"<blockquote>\n<p><strong>SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models</strong>\nVithursan Thangarasa, Abhay Gupta, William Marshall, Tianda Li, Kevin Leong, Dennis DeCoste, Sean Lie, Shreyas Saxena\n<a href=\"https://arxiv.org/abs/2303.10464\">https://arxiv.org/abs/2303.10464</a></p>\n</blockquote>\n<p>최근 NLP에서는 Pre-training과 Fine-tuning 패러다임이 사용되는데 이는 직접 downstream task에 훈련시키는 것이 아니라, 큰 데이터셋에서 Cross-domain knowledge를 이용해 먼저 언어 모델을 pre-training하고, 이후 task-specific 데이터에서 fine-tuning을 수행한다.  </p>\n<p>하지만, 모델과 데이터셋의 크기를 확장하면 성능 향상은 있지만 연산 비용도 크게 증가한다. 따라서 본 논문에서는 unstructured weight sparsity를 이용해 모델의 capacity를 pre-training과 fine-tuning 단계에서 분리하여 Sparse Pre-training and Dense Fine-tuning (SPDF)을 제안.  </p>\n<p>이를 통해, 1.3B parameter GPT-3 XL 모델에서 75% sparsity를 도출해 pre-training FLOPs를 2.5배 줄일 수 있었으며, downstream task의 정확도에도 큰 손실 없이 기존 dense 모델과 비슷한 결과를 보였줌.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 565px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 39.86486486486486%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsTAAALEwEAmpwYAAABhUlEQVQoz01Si26jMBDM/39JpfuIk06q7pSEJuGVay5HrsVEaVoI5mGDwcztOo2alczsztrDMmYGislaqKZBVVVomhbTNMHayaFqiZcSZVm6vr3rtXUF+dnTWrMUZvyodI8/xzPyokBT17iP5C3HqShRE1+T4C3MaLE/faCQV14r9SV4bns8xG/4/u8CUfd4L1sstgIfssXfUuOnKLEvFIYJEOcS3rOAVAY/0gSPQmB/qTHQ1PStV8Gcmt/iEwnmSKWG7gekZ4m2MziQ4CKTJNiiMSMUceJdQhuLRxL8lb0iuUiaePqckLyoadOFRMdxBNeWkcKSt3nbQdELmGOvmePozIBCafSEfIZ77OusIm+ePA8vhwPWqxXi7RYrwvV67TAMfERRiM1mg/l8juXSc3wcx/hNK/B9PFHN/SzLMGOzF4slET4877o5iiIEQeDQpwOc73Y7d+jGh2Ho8hvyAE6QrztNUxyPRwgyOEkSKLoxYwy6rnO/A6++7x134+9rznkNw4D/Xm9ZLadPtLYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"fig1\"\n        title=\"fig1\"\n        src=\"/static/4ee197064cb770510a48011f6ce047be/07eba/fig1.png\"\n        srcset=\"/static/4ee197064cb770510a48011f6ce047be/12f09/fig1.png 148w,\n/static/4ee197064cb770510a48011f6ce047be/e4a3f/fig1.png 295w,\n/static/4ee197064cb770510a48011f6ce047be/07eba/fig1.png 565w\"\n        sizes=\"(max-width: 565px) 100vw, 565px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 553px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.24324324324324%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABYElEQVQozz2Rha5DMQxD7///1qSBBhppzHDHzOj3jqWuUpQ0TR07iVarlQ6Hg6bTqZbLpdbrtRaLhT13YmqCJ4/fbDa/Wv5Te7vdFCUSCRWLRSWTSVuhUFA6nVYul1M+n3dcLpdVqVSUzWZdW61WXct7KpXyeyaT0X6/VwQqHa7Xqz3JYLvdzrntdmtGx+PRnjw+sOR+v9/1/X4V6f+QnM1mer1e6na7qtVqOp1Oms/nej6ffmu1Wno8Ho6RicThcKjxeOxcONH7/db5fDYAHyiO49hzwmDXbrdVr9fdOBhvg8HAjWAIGQMimQ50AhSwyWTiJZVKJcsCLHxkXtRCotPp+A0MjiXDitkwq8vlYpmAAYp04n6/r0ajYZm9Xs/MaEQNjZg3YGZIAEOKP5+Pu2Oj0chbRRobBhyGbJjZwbDZbNqC3B9DujErJAMOK6QzO+4AsCzAkQlLYurI8x8ynD/zOJul0M3hGQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table1\"\n        title=\"table1\"\n        src=\"/static/a0595f20aba9ba3a55f9652e41c5ec8f/74cfa/table1.png\"\n        srcset=\"/static/a0595f20aba9ba3a55f9652e41c5ec8f/12f09/table1.png 148w,\n/static/a0595f20aba9ba3a55f9652e41c5ec8f/e4a3f/table1.png 295w,\n/static/a0595f20aba9ba3a55f9652e41c5ec8f/74cfa/table1.png 553w\"\n        sizes=\"(max-width: 553px) 100vw, 553px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span>\n<span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 566px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 43.24324324324324%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABXklEQVQoz02RhwrCQBBE8/+fFUWNii0Se+9J7AWsI29DxIPhdm/Lzew64/FY8/lcw+FQ2Ok9Go00mUzM/n8HvV7PYmkd6Pf7ejwecjKZjFzXValUUj6fV7lcVqFQsDf8bDZrPvj3c7mcarWa6vW6oVqtJg3DMNRsNtNyuRT2fr9XFEXabDZarVZar9fa7Xb2Rhwfe7FY6HK56P1+6/P5/ODQ7HA4GPgRqdfr1XyaI8f3fbXbbQ0GA5MLo3QMEOHDOI4ThhSdTicDyTCAWVpEMjYjSWPFYtGawRgSoNlsJg2hDu73uzGAGX4QBGq1Wno+n+p0Ojaj4/FoH9Cg2+2aRBShgAVxnPP5bLO43W6aTqdGnSQK2BzzwqYpRQAlAHXkEEfN6/VKZsgCOLDabrdqNBomi40j0/O8n0xYVyoVi9GQURCn1hjCDKSLYJbcSAMo4OYjbGRj0wxl3PjUsPEvfZeQg4eV5ocAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table2\"\n        title=\"table2\"\n        src=\"/static/3d646071595318a305ac83824e0d120e/6fe44/table2.png\"\n        srcset=\"/static/3d646071595318a305ac83824e0d120e/12f09/table2.png 148w,\n/static/3d646071595318a305ac83824e0d120e/e4a3f/table2.png 295w,\n/static/3d646071595318a305ac83824e0d120e/6fe44/table2.png 566w\"\n        sizes=\"(max-width: 566px) 100vw, 566px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n      />\n    </span></p>","frontmatter":{"title":"SPDF: Sparse Pre-training and Dense Fine-tuning for Large Language Models","date":"April 16, 2023"}}},"pageContext":{"slug":"/NLP/spdf/","previous":{"fields":{"slug":"/Multi_Modal/beit3/"},"frontmatter":{"title":"[논문리뷰] Image as a Foreign Language: BEiT Pretraining for All Vision and Vision-Language Tasks","category":"Multi_Modal","draft":false}},"next":{"fields":{"slug":"/NLP/lecun_interview/"},"frontmatter":{"title":"AI 갓파더 얀 르쿤의 AI, LLM에 대한 인터뷰내용","category":"NLP","draft":false}}}},"staticQueryHashes":["3128451518","96099027"]}